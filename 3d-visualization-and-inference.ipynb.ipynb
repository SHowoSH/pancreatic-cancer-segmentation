{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install pandas tqdm scikit-learn matplotlib scipy tensorflow nibabel --quiet"],"metadata":{"id":"nxf6t7vC1h0o","executionInfo":{"status":"ok","timestamp":1750983424287,"user_tz":-540,"elapsed":9023,"user":{"displayName":"구글개정","userId":"15305168374719957285"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["!pip install Monai[all]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kbqxwXsG1l4z","executionInfo":{"status":"ok","timestamp":1750983616077,"user_tz":-540,"elapsed":191772,"user":{"displayName":"구글개정","userId":"15305168374719957285"}},"outputId":"69be79e2-10ba-4909-8d5a-6661c32b9707"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting Monai[all]\n","  Downloading monai-1.5.0-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: numpy<3.0,>=1.24 in /usr/local/lib/python3.11/dist-packages (from Monai[all]) (2.0.2)\n","Requirement already satisfied: torch<2.7.0,>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from Monai[all]) (2.6.0+cu124)\n","Collecting clearml>=1.10.0rc0 (from Monai[all])\n","  Downloading clearml-2.0.1-py2.py3-none-any.whl.metadata (17 kB)\n","Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from Monai[all]) (0.8.1)\n","Collecting fire (from Monai[all])\n","  Downloading fire-0.7.0.tar.gz (87 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: gdown>=4.7.3 in /usr/local/lib/python3.11/dist-packages (from Monai[all]) (5.2.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from Monai[all]) (3.14.0)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from Monai[all]) (0.33.0)\n","Collecting itk>=5.2 (from Monai[all])\n","  Downloading itk-5.4.4.post1-cp311-abi3-manylinux_2_28_x86_64.whl.metadata (22 kB)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from Monai[all]) (4.24.0)\n","Collecting lmdb (from Monai[all])\n","  Downloading lmdb-1.6.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n","Collecting lpips==0.1.4 (from Monai[all])\n","  Downloading lpips-0.1.4-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: matplotlib>=3.6.3 in /usr/local/lib/python3.11/dist-packages (from Monai[all]) (3.10.0)\n","Collecting mlflow>=2.12.2 (from Monai[all])\n","  Downloading mlflow-3.1.1-py3-none-any.whl.metadata (29 kB)\n","Requirement already satisfied: nibabel in /usr/local/lib/python3.11/dist-packages (from Monai[all]) (5.3.2)\n","Collecting ninja (from Monai[all])\n","  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n","Requirement already satisfied: nvidia-ml-py in /usr/local/lib/python3.11/dist-packages (from Monai[all]) (12.575.51)\n","Collecting onnx>=1.13.0 (from Monai[all])\n","  Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n","Collecting openslide-bin (from Monai[all])\n","  Downloading openslide_bin-4.0.0.8-py3-none-manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n","Collecting openslide-python (from Monai[all])\n","  Downloading openslide_python-1.4.2-cp311-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (4.9 kB)\n","Collecting optuna (from Monai[all])\n","  Downloading optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from Monai[all]) (2.2.2)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from Monai[all]) (11.2.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from Monai[all]) (5.9.5)\n","Collecting pyamg>=5.0.0 (from Monai[all])\n","  Downloading pyamg-5.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n","Collecting pydicom (from Monai[all])\n","  Downloading pydicom-3.0.1-py3-none-any.whl.metadata (9.4 kB)\n","Collecting pynrrd (from Monai[all])\n","  Downloading pynrrd-1.1.3-py3-none-any.whl.metadata (5.4 kB)\n","Collecting pytorch-ignite==0.4.11 (from Monai[all])\n","  Downloading pytorch_ignite-0.4.11-py3-none-any.whl.metadata (28 kB)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from Monai[all]) (6.0.2)\n","Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.11/dist-packages (from Monai[all]) (0.25.2)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from Monai[all]) (2.18.0)\n","Collecting tensorboardX (from Monai[all])\n","  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n","Collecting torchio (from Monai[all])\n","  Downloading torchio-0.20.14-py3-none-any.whl.metadata (52 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.1/52.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from Monai[all]) (0.21.0+cu124)\n","Requirement already satisfied: tqdm>=4.47.0 in /usr/local/lib/python3.11/dist-packages (from Monai[all]) (4.67.1)\n","Collecting zarr (from Monai[all])\n","  Downloading zarr-3.0.8-py3-none-any.whl.metadata (10.0 kB)\n","Collecting nni (from Monai[all])\n","  Downloading nni-3.0-py3-none-manylinux1_x86_64.whl.metadata (19 kB)\n","Collecting imagecodecs (from Monai[all])\n","  Downloading imagecodecs-2025.3.30-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n","Requirement already satisfied: tifffile in /usr/local/lib/python3.11/dist-packages (from Monai[all]) (2025.6.11)\n","Requirement already satisfied: scipy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from Monai[all]) (1.15.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pytorch-ignite==0.4.11->Monai[all]) (24.2)\n","Requirement already satisfied: attrs>=18.0 in /usr/local/lib/python3.11/dist-packages (from clearml>=1.10.0rc0->Monai[all]) (25.3.0)\n","Collecting furl>=2.0.0 (from clearml>=1.10.0rc0->Monai[all])\n","  Downloading furl-2.1.4-py2.py3-none-any.whl.metadata (25 kB)\n","Collecting pathlib2>=2.3.0 (from clearml>=1.10.0rc0->Monai[all])\n","  Downloading pathlib2-2.3.7.post1-py2.py3-none-any.whl.metadata (3.5 kB)\n","Requirement already satisfied: pyparsing>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from clearml>=1.10.0rc0->Monai[all]) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.11/dist-packages (from clearml>=1.10.0rc0->Monai[all]) (2.9.0.post0)\n","Requirement already satisfied: pyjwt<2.11.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from clearml>=1.10.0rc0->Monai[all]) (2.10.1)\n","Requirement already satisfied: six>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from clearml>=1.10.0rc0->Monai[all]) (1.17.0)\n","Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from clearml>=1.10.0rc0->Monai[all]) (2.4.0)\n","Requirement already satisfied: referencing<0.40 in /usr/local/lib/python3.11/dist-packages (from clearml>=1.10.0rc0->Monai[all]) (0.36.2)\n","Requirement already satisfied: requests>=2.32.0 in /usr/local/lib/python3.11/dist-packages (from clearml>=1.10.0rc0->Monai[all]) (2.32.3)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown>=4.7.3->Monai[all]) (4.13.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown>=4.7.3->Monai[all]) (3.18.0)\n","Collecting itk-core==5.4.4.post1 (from itk>=5.2->Monai[all])\n","  Downloading itk_core-5.4.4.post1-cp311-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (22 kB)\n","Collecting itk-numerics==5.4.4.post1 (from itk>=5.2->Monai[all])\n","  Downloading itk_numerics-5.4.4.post1-cp311-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (22 kB)\n","Collecting itk-io==5.4.4.post1 (from itk>=5.2->Monai[all])\n","  Downloading itk_io-5.4.4.post1-cp311-abi3-manylinux_2_28_x86_64.whl.metadata (22 kB)\n","Collecting itk-filtering==5.4.4.post1 (from itk>=5.2->Monai[all])\n","  Downloading itk_filtering-5.4.4.post1-cp311-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (22 kB)\n","Collecting itk-registration==5.4.4.post1 (from itk>=5.2->Monai[all])\n","  Downloading itk_registration-5.4.4.post1-cp311-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (22 kB)\n","Collecting itk-segmentation==5.4.4.post1 (from itk>=5.2->Monai[all])\n","  Downloading itk_segmentation-5.4.4.post1-cp311-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (22 kB)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->Monai[all]) (2025.4.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->Monai[all]) (0.25.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.3->Monai[all]) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.3->Monai[all]) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.3->Monai[all]) (4.58.4)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.3->Monai[all]) (1.4.8)\n","Collecting mlflow-skinny==3.1.1 (from mlflow>=2.12.2->Monai[all])\n","  Downloading mlflow_skinny-3.1.1-py3-none-any.whl.metadata (30 kB)\n","Requirement already satisfied: Flask<4 in /usr/local/lib/python3.11/dist-packages (from mlflow>=2.12.2->Monai[all]) (3.1.1)\n","Collecting alembic!=1.10.0,<2 (from mlflow>=2.12.2->Monai[all])\n","  Downloading alembic-1.16.2-py3-none-any.whl.metadata (7.3 kB)\n","Collecting docker<8,>=4.0.0 (from mlflow>=2.12.2->Monai[all])\n","  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n","Collecting graphene<4 (from mlflow>=2.12.2->Monai[all])\n","  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n","Collecting gunicorn<24 (from mlflow>=2.12.2->Monai[all])\n","  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n","Requirement already satisfied: pyarrow<21,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow>=2.12.2->Monai[all]) (18.1.0)\n","Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.11/dist-packages (from mlflow>=2.12.2->Monai[all]) (1.6.1)\n","Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow>=2.12.2->Monai[all]) (2.0.41)\n","Requirement already satisfied: cachetools<7,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=2.12.2->Monai[all]) (5.5.2)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=2.12.2->Monai[all]) (8.2.1)\n","Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=2.12.2->Monai[all]) (3.1.1)\n","Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.1.1->mlflow>=2.12.2->Monai[all])\n","  Downloading databricks_sdk-0.57.0-py3-none-any.whl.metadata (39 kB)\n","Requirement already satisfied: fastapi<1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=2.12.2->Monai[all]) (0.115.13)\n","Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=2.12.2->Monai[all]) (3.1.44)\n","Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=2.12.2->Monai[all]) (8.7.0)\n","Collecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==3.1.1->mlflow>=2.12.2->Monai[all])\n","  Downloading opentelemetry_api-1.34.1-py3-none-any.whl.metadata (1.5 kB)\n","Collecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==3.1.1->mlflow>=2.12.2->Monai[all])\n","  Downloading opentelemetry_sdk-1.34.1-py3-none-any.whl.metadata (1.6 kB)\n","Requirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=2.12.2->Monai[all]) (5.29.5)\n","Requirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=2.12.2->Monai[all]) (2.11.7)\n","Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=2.12.2->Monai[all]) (0.5.3)\n","Requirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=2.12.2->Monai[all]) (4.14.0)\n","Requirement already satisfied: uvicorn<1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=2.12.2->Monai[all]) (0.34.3)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->Monai[all]) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->Monai[all]) (2025.2)\n","Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.14.2->Monai[all]) (3.5)\n","Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.14.2->Monai[all]) (2.37.0)\n","Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.14.2->Monai[all]) (0.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->Monai[all]) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->Monai[all]) (2025.3.2)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<2.7.0,>=2.4.1->Monai[all])\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<2.7.0,>=2.4.1->Monai[all])\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<2.7.0,>=2.4.1->Monai[all])\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<2.7.0,>=2.4.1->Monai[all])\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<2.7.0,>=2.4.1->Monai[all])\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<2.7.0,>=2.4.1->Monai[all])\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch<2.7.0,>=2.4.1->Monai[all])\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<2.7.0,>=2.4.1->Monai[all])\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<2.7.0,>=2.4.1->Monai[all])\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->Monai[all]) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->Monai[all]) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->Monai[all]) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<2.7.0,>=2.4.1->Monai[all])\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->Monai[all]) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->Monai[all]) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<2.7.0,>=2.4.1->Monai[all]) (1.3.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire->Monai[all]) (3.1.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->Monai[all]) (1.1.5)\n","Requirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.11/dist-packages (from nibabel->Monai[all]) (6.5.2)\n","Collecting astor (from nni->Monai[all])\n","  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n","Collecting colorama (from nni->Monai[all])\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n","Collecting filelock (from gdown>=4.7.3->Monai[all])\n","  Downloading filelock-3.11.0-py3-none-any.whl.metadata (2.5 kB)\n","Collecting json-tricks>=3.15.5 (from nni->Monai[all])\n","  Downloading json_tricks-3.17.3-py2.py3-none-any.whl.metadata (16 kB)\n","Requirement already satisfied: prettytable in /usr/local/lib/python3.11/dist-packages (from nni->Monai[all]) (3.16.0)\n","Collecting PythonWebHDFS (from nni->Monai[all])\n","  Downloading PythonWebHDFS-0.2.3-py3-none-any.whl.metadata (717 bytes)\n","Collecting responses (from nni->Monai[all])\n","  Downloading responses-0.25.7-py3-none-any.whl.metadata (47 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting schema (from nni->Monai[all])\n","  Downloading schema-0.7.7-py2.py3-none-any.whl.metadata (34 kB)\n","Collecting typeguard<4.1.3,>=3.0.0 (from nni->Monai[all])\n","  Downloading typeguard-4.1.2-py3-none-any.whl.metadata (3.7 kB)\n","Requirement already satisfied: websockets>=10.1 in /usr/local/lib/python3.11/dist-packages (from nni->Monai[all]) (15.0.1)\n","Collecting colorlog (from optuna->Monai[all])\n","  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->Monai[all]) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->Monai[all]) (1.73.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->Monai[all]) (3.8.2)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->Monai[all]) (75.2.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->Monai[all]) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->Monai[all]) (3.1.3)\n","Collecting deprecated>=1.2 (from torchio->Monai[all])\n","  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n","Requirement already satisfied: humanize>=0.1 in /usr/local/lib/python3.11/dist-packages (from torchio->Monai[all]) (4.12.3)\n","Requirement already satisfied: rich>=10 in /usr/local/lib/python3.11/dist-packages (from torchio->Monai[all]) (13.9.4)\n","Collecting simpleitk!=2.0.*,!=2.1.1.1,>=1.3 (from torchio->Monai[all])\n","  Downloading simpleitk-2.5.2-cp311-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (7.2 kB)\n","Requirement already satisfied: typer>=0.1 in /usr/local/lib/python3.11/dist-packages (from torchio->Monai[all]) (0.16.0)\n","Collecting donfig>=0.8 (from zarr->Monai[all])\n","  Downloading donfig-0.8.1.post1-py3-none-any.whl.metadata (5.0 kB)\n","Collecting numcodecs>=0.14 (from numcodecs[crc32c]>=0.14->zarr->Monai[all])\n","  Downloading numcodecs-0.16.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n","Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic!=1.10.0,<2->mlflow>=2.12.2->Monai[all]) (1.1.3)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2->torchio->Monai[all]) (1.17.2)\n","Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow>=2.12.2->Monai[all]) (1.9.0)\n","Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow>=2.12.2->Monai[all]) (2.2.0)\n","Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow>=2.12.2->Monai[all]) (3.0.2)\n","Collecting orderedmultidict>=1.0.1 (from furl>=2.0.0->clearml>=1.10.0rc0->Monai[all])\n","  Downloading orderedmultidict-1.0.1-py2.py3-none-any.whl.metadata (1.3 kB)\n","Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow>=2.12.2->Monai[all])\n","  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n","Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow>=2.12.2->Monai[all])\n","  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n","Collecting crc32c>=2.7 (from numcodecs[crc32c]>=0.14->zarr->Monai[all])\n","  Downloading crc32c-2.7.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.0->clearml>=1.10.0rc0->Monai[all]) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.0->clearml>=1.10.0rc0->Monai[all]) (3.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.0->clearml>=1.10.0rc0->Monai[all]) (2025.6.15)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10->torchio->Monai[all]) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10->torchio->Monai[all]) (2.19.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow>=2.12.2->Monai[all]) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow>=2.12.2->Monai[all]) (3.6.0)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow>=2.12.2->Monai[all]) (3.2.3)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.1->torchio->Monai[all]) (1.5.4)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown>=4.7.3->Monai[all]) (2.7)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prettytable->nni->Monai[all]) (0.2.13)\n","Requirement already satisfied: simplejson in /usr/local/lib/python3.11/dist-packages (from PythonWebHDFS->nni->Monai[all]) (3.20.1)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.7.3->Monai[all]) (1.7.1)\n","Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.11/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow>=2.12.2->Monai[all]) (2.38.0)\n","Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi<1->mlflow-skinny==3.1.1->mlflow>=2.12.2->Monai[all]) (0.46.2)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.1.1->mlflow>=2.12.2->Monai[all]) (4.0.12)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.1.1->mlflow>=2.12.2->Monai[all]) (3.23.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10->torchio->Monai[all]) (0.1.2)\n","Collecting opentelemetry-semantic-conventions==0.55b1 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.1.1->mlflow>=2.12.2->Monai[all])\n","  Downloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow>=2.12.2->Monai[all]) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow>=2.12.2->Monai[all]) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow>=2.12.2->Monai[all]) (0.4.1)\n","Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn<1->mlflow-skinny==3.1.1->mlflow>=2.12.2->Monai[all]) (0.16.0)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.1.1->mlflow>=2.12.2->Monai[all]) (5.0.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow>=2.12.2->Monai[all]) (0.4.2)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow>=2.12.2->Monai[all]) (4.9.1)\n","Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==3.1.1->mlflow>=2.12.2->Monai[all]) (4.9.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==3.1.1->mlflow>=2.12.2->Monai[all]) (1.3.1)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow>=2.12.2->Monai[all]) (0.6.1)\n","Downloading lpips-0.1.4-py3-none-any.whl (53 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pytorch_ignite-0.4.11-py3-none-any.whl (266 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.5/266.5 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading clearml-2.0.1-py2.py3-none-any.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading itk-5.4.4.post1-cp311-abi3-manylinux_2_28_x86_64.whl (16 kB)\n","Downloading itk_core-5.4.4.post1-cp311-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (80.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.9/80.9 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading itk_filtering-5.4.4.post1-cp311-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (67.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading itk_io-5.4.4.post1-cp311-abi3-manylinux_2_28_x86_64.whl (28.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.0/28.0 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading itk_numerics-5.4.4.post1-cp311-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (57.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.2/57.2 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading itk_registration-5.4.4.post1-cp311-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (28.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.5/28.5 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading itk_segmentation-5.4.4.post1-cp311-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (15.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mlflow-3.1.1-py3-none-any.whl (24.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.7/24.7 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mlflow_skinny-3.1.1-py3-none-any.whl (1.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m90.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyamg-5.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading imagecodecs-2025.3.30-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (45.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.6/45.6 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lmdb-1.6.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (297 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.8/297.8 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading monai-1.5.0-py3-none-any.whl (2.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nni-3.0-py3-none-manylinux1_x86_64.whl (61.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/61.4 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading openslide_bin-4.0.0.8-py3-none-manylinux_2_28_x86_64.whl (4.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading openslide_python-1.4.2-cp311-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.whl (36 kB)\n","Downloading optuna-4.4.0-py3-none-any.whl (395 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pydicom-3.0.1-py3-none-any.whl (2.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pynrrd-1.1.3-py3-none-any.whl (23 kB)\n","Downloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchio-0.20.14-py3-none-any.whl (186 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m186.9/186.9 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading zarr-3.0.8-py3-none-any.whl (205 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.4/205.4 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading alembic-1.16.2-py3-none-any.whl (242 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.7/242.7 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n","Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading donfig-0.8.1.post1-py3-none-any.whl (21 kB)\n","Downloading filelock-3.11.0-py3-none-any.whl (10.0 kB)\n","Downloading furl-2.1.4-py2.py3-none-any.whl (27 kB)\n","Downloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading json_tricks-3.17.3-py2.py3-none-any.whl (27 kB)\n","Downloading numcodecs-0.16.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pathlib2-2.3.7.post1-py2.py3-none-any.whl (18 kB)\n","Downloading simpleitk-2.5.2-cp311-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (52.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading typeguard-4.1.2-py3-none-any.whl (33 kB)\n","Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n","Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n","Downloading PythonWebHDFS-0.2.3-py3-none-any.whl (10 kB)\n","Downloading responses-0.25.7-py3-none-any.whl (34 kB)\n","Downloading schema-0.7.7-py2.py3-none-any.whl (18 kB)\n","Downloading crc32c-2.7.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.7/53.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading databricks_sdk-0.57.0-py3-none-any.whl (733 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m733.8/733.8 kB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n","Downloading opentelemetry_api-1.34.1-py3-none-any.whl (65 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_sdk-1.34.1-py3-none-any.whl (118 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl (196 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading orderedmultidict-1.0.1-py2.py3-none-any.whl (11 kB)\n","Building wheels for collected packages: fire\n","  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=9a46051532325c9b9b3fee53235c8fe23e411c545d25f24f78f9e779d2daa09f\n","  Stored in directory: /root/.cache/pip/wheels/46/54/24/1624fd5b8674eb1188623f7e8e17cdf7c0f6c24b609dfb8a89\n","Successfully built fire\n","Installing collected packages: simpleitk, schema, lmdb, json-tricks, typeguard, tensorboardX, pynrrd, pydicom, pathlib2, orderedmultidict, openslide-python, openslide-bin, onnx, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numcodecs, ninja, itk-core, imagecodecs, gunicorn, graphql-core, fire, filelock, donfig, deprecated, crc32c, colorlog, colorama, astor, responses, PythonWebHDFS, pyamg, opentelemetry-api, nvidia-cusparse-cu12, nvidia-cudnn-cu12, itk-numerics, itk-io, graphql-relay, furl, docker, alembic, zarr, optuna, opentelemetry-semantic-conventions, nvidia-cusolver-cu12, nni, itk-filtering, graphene, databricks-sdk, opentelemetry-sdk, itk-segmentation, itk-registration, clearml, torchio, pytorch-ignite, Monai, mlflow-skinny, itk, mlflow, lpips\n","  Attempting uninstall: typeguard\n","    Found existing installation: typeguard 4.4.4\n","    Uninstalling typeguard-4.4.4:\n","      Successfully uninstalled typeguard-4.4.4\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: filelock\n","    Found existing installation: filelock 3.18.0\n","    Uninstalling filelock-3.18.0:\n","      Successfully uninstalled filelock-3.18.0\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","pytensor 2.31.3 requires filelock>=3.15, but you have filelock 3.11.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed Monai-1.5.0 PythonWebHDFS-0.2.3 alembic-1.16.2 astor-0.8.1 clearml-2.0.1 colorama-0.4.6 colorlog-6.9.0 crc32c-2.7.1 databricks-sdk-0.57.0 deprecated-1.2.18 docker-7.1.0 donfig-0.8.1.post1 filelock-3.11.0 fire-0.7.0 furl-2.1.4 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 gunicorn-23.0.0 imagecodecs-2025.3.30 itk-5.4.4.post1 itk-core-5.4.4.post1 itk-filtering-5.4.4.post1 itk-io-5.4.4.post1 itk-numerics-5.4.4.post1 itk-registration-5.4.4.post1 itk-segmentation-5.4.4.post1 json-tricks-3.17.3 lmdb-1.6.2 lpips-0.1.4 mlflow-3.1.1 mlflow-skinny-3.1.1 ninja-1.11.1.4 nni-3.0 numcodecs-0.16.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 onnx-1.18.0 openslide-bin-4.0.0.8 openslide-python-1.4.2 opentelemetry-api-1.34.1 opentelemetry-sdk-1.34.1 opentelemetry-semantic-conventions-0.55b1 optuna-4.4.0 orderedmultidict-1.0.1 pathlib2-2.3.7.post1 pyamg-5.2.1 pydicom-3.0.1 pynrrd-1.1.3 pytorch-ignite-0.4.11 responses-0.25.7 schema-0.7.7 simpleitk-2.5.2 tensorboardX-2.6.4 torchio-0.20.14 typeguard-4.1.2 zarr-3.0.8\n"]}]},{"cell_type":"code","source":["# # Colab에 맞게 numpy와 관련 패키지 재설치\n","!pip install --upgrade --force-reinstall numpy\n","!pip install --upgrade --force-reinstall pandas scipy scikit-learn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Cf3Ari_53mi0","executionInfo":{"status":"ok","timestamp":1750983681110,"user_tz":-540,"elapsed":65030,"user":{"displayName":"구글개정","userId":"15305168374719957285"}},"outputId":"436b6951-a90f-43b6-a2eb-a384fbbbd36a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting numpy\n","  Downloading numpy-2.3.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-2.3.1-cp311-cp311-manylinux_2_28_x86_64.whl (16.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.9/16.9 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: numpy\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 2.0.2\n","    Uninstalling numpy-2.0.2:\n","      Successfully uninstalled numpy-2.0.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.1 which is incompatible.\n","cupy-cuda12x 13.3.0 requires numpy<2.3,>=1.22, but you have numpy 2.3.1 which is incompatible.\n","pytensor 2.31.3 requires filelock>=3.15, but you have filelock 3.11.0 which is incompatible.\n","tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.3.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed numpy-2.3.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]},"id":"e2ca2db176734712a699e9671d1c20a4"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting pandas\n","  Downloading pandas-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting scipy\n","  Downloading scipy-1.16.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting scikit-learn\n","  Downloading scikit_learn-1.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (17 kB)\n","Collecting numpy>=1.23.2 (from pandas)\n","  Using cached numpy-2.3.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (62 kB)\n","Collecting python-dateutil>=2.8.2 (from pandas)\n","  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n","Collecting pytz>=2020.1 (from pandas)\n","  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n","Collecting tzdata>=2022.7 (from pandas)\n","  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n","Collecting joblib>=1.2.0 (from scikit-learn)\n","  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n","Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n","  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n","Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas)\n","  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n","Downloading pandas-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m106.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading scipy-1.16.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.3/35.3 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading scikit_learn-1.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m97.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading joblib-1.5.1-py3-none-any.whl (307 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hUsing cached numpy-2.3.1-cp311-cp311-manylinux_2_28_x86_64.whl (16.9 MB)\n","Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n","Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n","Installing collected packages: pytz, tzdata, threadpoolctl, six, numpy, joblib, scipy, python-dateutil, scikit-learn, pandas\n","  Attempting uninstall: pytz\n","    Found existing installation: pytz 2025.2\n","    Uninstalling pytz-2025.2:\n","      Successfully uninstalled pytz-2025.2\n","  Attempting uninstall: tzdata\n","    Found existing installation: tzdata 2025.2\n","    Uninstalling tzdata-2025.2:\n","      Successfully uninstalled tzdata-2025.2\n","  Attempting uninstall: threadpoolctl\n","    Found existing installation: threadpoolctl 3.6.0\n","    Uninstalling threadpoolctl-3.6.0:\n","      Successfully uninstalled threadpoolctl-3.6.0\n","  Attempting uninstall: six\n","    Found existing installation: six 1.17.0\n","    Uninstalling six-1.17.0:\n","      Successfully uninstalled six-1.17.0\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 2.3.1\n","    Uninstalling numpy-2.3.1:\n","      Successfully uninstalled numpy-2.3.1\n","  Attempting uninstall: joblib\n","    Found existing installation: joblib 1.5.1\n","    Uninstalling joblib-1.5.1:\n","      Successfully uninstalled joblib-1.5.1\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.15.3\n","    Uninstalling scipy-1.15.3:\n","      Successfully uninstalled scipy-1.15.3\n","  Attempting uninstall: python-dateutil\n","    Found existing installation: python-dateutil 2.9.0.post0\n","    Uninstalling python-dateutil-2.9.0.post0:\n","      Successfully uninstalled python-dateutil-2.9.0.post0\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.6.1\n","    Uninstalling scikit-learn-1.6.1:\n","      Successfully uninstalled scikit-learn-1.6.1\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 2.2.2\n","    Uninstalling pandas-2.2.2:\n","      Successfully uninstalled pandas-2.2.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.0 which is incompatible.\n","numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.1 which is incompatible.\n","dask-cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.0 which is incompatible.\n","sklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.7.0 which is incompatible.\n","cudf-cu12 25.2.1 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.0 which is incompatible.\n","cupy-cuda12x 13.3.0 requires numpy<2.3,>=1.22, but you have numpy 2.3.1 which is incompatible.\n","pytensor 2.31.3 requires filelock>=3.15, but you have filelock 3.11.0 which is incompatible.\n","tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.3.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed joblib-1.5.1 numpy-2.3.1 pandas-2.3.0 python-dateutil-2.9.0.post0 pytz-2025.2 scikit-learn-1.7.0 scipy-1.16.0 six-1.17.0 threadpoolctl-3.6.0 tzdata-2025.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["dateutil","numpy","six"]},"id":"c74f7058521341ebb915053a2d6e407b"}},"metadata":{}}]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"mhSjHNSo1aF1","executionInfo":{"status":"ok","timestamp":1750983830185,"user_tz":-540,"elapsed":44995,"user":{"displayName":"구글개정","userId":"15305168374719957285"}},"outputId":"34c5b935-e91a-4a7e-ab11-271ba192122c"},"outputs":[{"output_type":"stream","name":"stdout","text":["--- 췌장 Multi-Class 세분화 추론 스크립트 ---\n","사용 장치: cpu\n","모델 로딩 중 'Custom3DUNet' from: /content/drive/MyDrive/2조/췌장암 영상/췌장암_로컬_수정/20250405-151938/checkpoints/best_model_20250405-151938.pth\n","Custom3DUNet 로드 완료 (out_channels=3)\n","모델 상태 로드 완료 (epoch 96)\n","모델 로드 및 평가 모드 설정 완료.\n","\n","추론 시작: /content/drive/MyDrive/2조/췌장암 영상/췌장암_로컬_수정/pancreas_025.nii\n","전처리 변환 적용 중...\n","전처리 완료. 입력 텐서 shape: torch.Size([1, 64, 96, 96])\n","모델 추론 실행 중...\n","추론 완료. 출력 로짓 shape: torch.Size([1, 3, 64, 96, 96])\n","후처리 변환 적용 중...\n","후처리 완료. 최종 마스크 shape: torch.Size([1, 64, 96, 96])\n","추론 소요 시간: 4.94 초.\n","\n","초기 확인: 모델 예측 결과에 종양 레이블(2) 포함됨.\n","\n","3D 시각화 생성 중...\n","시각화용 마스크 shape: (64, 96, 96)\n","마스크 내 고유 값: [0 1 2]\n","췌장(레이블 1) 메쉬 생성 중...\n","--- 세분화 마스크 기반: 췌장 감지됨 ---\n","췌장 메쉬 생성 완료.\n","종양(레이블 2) 메쉬 생성 중...\n","--- 세분화 마스크 기반: 암(종양) 감지됨 ---\n","종양 메쉬 생성 완료.\n","인터랙티브 3D 플롯 표시 중...\n"]},{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"04013e28-90cc-47c7-b43f-6d0cbc5c9496\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"04013e28-90cc-47c7-b43f-6d0cbc5c9496\")) {                    Plotly.newPlot(                        \"04013e28-90cc-47c7-b43f-6d0cbc5c9496\",                        [{\"color\":\"rgb(107, 174, 214)\",\"i\":[0,2,4,5,6,6,7,6,4,7,10,8,2,1,3,3,2,13,16,16,18,20,20,5,3,8,6,6,6,22,21,23,26,27,20,28,5,5,20,9,29,10,10,30,24,32,33,32,26,34,34,26,29,37,30,38,39,39,38,32,41,33,35,37,43,38,44,39,12,46,46,47,47,48,18,17,19,18,45,45,52,46,15,21,23,21,54,55,56,56,56,27,25,55,60,61,27,27,56,34,40,64,64,65,59,65,60,66,66,60,36,36,62,42,69,71,71,72,63,63,73,64,67,69,75,70,76,71,47,47,50,79,79,80,52,51,77,77,82,48,48,53,84,84,54,54,58,57,78,78,88,79,84,89,89,90,57,86,65,65,65,59,94,94,95,66,72,97,97,98,92,92,99,93,94,101,74,74,74,74,101,75,103,76,71,71,71,97,101,103,108,104,109,105,80,80,110,81,111,82,112,83,87,87,114,88,79,79,79,111,118,112,119,113,120,85,85,89,121,122,114,114,86,115,125,116,126,126,126,93,91,123,98,126,126,126,130,93,132,132,133,100,106,106,106,134,136,135,137,138,102,102,132,107,139,108,140,109,109,141,143,143,142,136,137,145,145,137,140,148,141,149,150,150,149,143,146,148,153,149,154,150,117,117,155,118,156,119,157,120,158,121,124,124,160,125,116,116,116,156,164,157,165,158,166,127,127,127,158,122,160,123,169,169,168,162,128,167,168,168,129,169,131,171,133,172,144,177,177,177,176,177,180,180,181,145,151,151,151,182,184,184,183,179,186,187,147,147,180,152,188,153,189,154,154,190,192,192,191,184,194,195,188,196,197,197,196,190,199,191,200,192,194,196,202,197,163,163,203,164,204,165,205,166,170,170,170,207,204,209,205,210,206,211,167,206,173,173,173,212,208,214,215,215,214,210,217,211,218,218,218,219,212,172,221,221,220,214,223,215,174,177,224,225,220,220,175,221,185,229,229,229,228,229,232,232,232,187,193,193,193,235,230,237,238,237,239,240,187,232,198,198,241,199,242,200,200,243,236,245,237,246,247,246,248,240,240,239,195,195,239,201,252,202,202,253,242,255,243,256,244,257,245,258,259,259,258,247,248,251,262,252,263,253,264,254,265,255,266,256,267,257,268,258,269,259,216,216,270,217,271,218,222,222,273,223,223,274,271,276,272,277,219,219,272,224,227,227,227,279,274,281,275,282,276,283,277,284,278,285,225,225,278,229,234,234,234,287,280,289,290,290,289,282,292,292,292,282,295,295,294,296,296,284,286,299,231,286,287,233,301,301,300,289,303,290,294,295,298,305,305,298,238,299,250,249,300,300,310,301,311,306,313,313,313,247,314,314,315,261,314,262,316,263,317,264,318,265,319,266,320,267,321,268,322,269,259,259,259,313,314,326,326,314,317,329,318,330,319,331,320,332,321,333,322,334,335,335,334,324,327,337,337,327,340,340,338,331,342,332,343,333,344,334,345,335,338,340,291,291,347,292,296,296,350,350,352,354,353,355,302,302,358,303,303,359,348,361,293,293,348,304,304,362,297,297,349,305,350,354,366,356,367,357,309,309,368,310,310,369,359,371,360,372,373,373,372,362,375,363,376,376,376,363,306,306,364,312,368,308,381,381,380,370,383,371,384,372,385,373,386,387,325,325,379,313,388,388,380,380,390,328,336,336,335,324,392,392,394,388,388,389,328,328,389,337,341,341,399,342,400,402,402,403,345,344,391,404,392,396,406,397,407,398,408,339,339,346,399,399,410,400,411,401,412,402,413,415,417,417,419,421,420,423,422,425,424,427,426,429,428,414,414,413,433,433,434,433,436,418,418,417,352,352,421,353,423,353,353,441,423,442,440,423,440,441,441,357,425,445,429,446,431,447,432,448,434,449,450,450,451,450,436,453,453,436,351,351,439,365,456,367,458,442,366,459,457,458,367,458,441,367,445,460,462,462,461,463,463,446,448,466,449,467,468,468,467,452,374,374,470,375,471,376,454,456,474,474,474,456,460,477,461,478,479,479,480,480,480,480,464,466,483,483,483,466,486,484,382,488,488,489,384,383,385,384,470,470,492,492,492,470,472,495,377,472,475,477,497,497,497,477,480,500,501,500,484,486,390,390,381,381,381,488,506,493,493,494,495,510,387,495,498,511,511,498,514,512,394,394,515,395,395,516,518,517,519,508,508,506,403,403,509,404,510,391,512,512,512,512,525,525,526,529,393,527,405,528,531,515,530,406,533,516,532,407,533,535,407,536,409,408,410,409,521,521,538,412,522,402,525,528,540,530,541,532,542,534,543,535,544,544,546,548,547,549,415,415,553,553,553,555,545,545,556,422,548,424,550,550,550,424,428,426,430,428,552,552,560,416,416,433,561,562,438,438,437,418,564,564,565,567,567,568,444,444,443,570,571,573,575,575,576,450,577,577,578,453,579,580,567,581,442,442,567,459,459,582,463,463,572,465,463,463,463,584,585,587,469,469,468,452,577,455,455,473,579,591,593,473,474,595,592,581,582,597,583,598,462,462,583,599,599,599,584,483,586,485,483,483,483,602,603,486,589,604,603,605,489,489,608,490,609,491,610,492,593,593,496,595,595,615,614,612,596,596,616,595,613,497,618,618,617,598,499,619,598,619,617,618,618,598,482,599,485,602,502,622,486,623,606,624,504,504,504,607,608,608,626,626,626,608,610,629,507,507,611,493,613,617,631,499,499,511,511,511,620,513,621,633,513,633,620,634,634,636,637,622,622,623,624,641,504,624,642,627,627,628,520,520,629,508,513,523,636,526,646,647,523,526,647,527,637,648,638,650,649,651,640,529,652,653,641,531,641,536,653,655,644,644,655,538,645,521,524,540,648,541,650,542,651,543,653,535,656,658,658,658,546,546,660,547,661,549,555,554,657,657,664,659,556,661,666,662,667,551,551,557,669,669,558,558,669,559,671,560,672,561,554,663,565,676,676,677,569,568,679,679,571,573,681,670,571,682,679,681,573,681,573,684,682,671,672,686,673,687,562,673,688,688,674,688,675,566,692,691,679,683,694,683,585,684,684,697,696,694,685,685,587,695,686,698,684,588,588,699,576,687,578,689,689,590,591,701,691,700,592,702,701,591,701,596,592,592,592,703,706,697,697,695,710,710,711,712,588,710,601,711,713,714,699,601,699,602,589,715,713,603,715,605,594,612,612,718,704,717,614,719,718,612,718,704,704,614,618,616,620,620,620,721,709,723,711,724,713,725,622,622,715,725,727,726,725,726,715,727,727,715,607,607,716,625,730,626,615,630,631,630,632,631,634,635,736,632,735,636,722,738,739,739,738,740,741,724,638,725,742,743,622,744,639,745,743,742,743,728,728,729,730,747,643,643,731,627,635,646,646,646,748,739,638,652,745,654,746,655,747,644,658,658,664,664,664,750,659,659,749,665,752,666,753,667,754,668,750,663,751,757,752,758,677,677,753,678,760,677,761,753,762,762,759,755,680,763,755,763,759,764,682,682,682,682,674,690,690,766,767,767,766,758,758,758,770,760,760,759,680,680,759,694,773,765,693,774,772,773,694,773,775,776,764,694,764,697,685,777,775,696,690,702,700,700,700,770,780,705,705,781,772,782,783,708,782,775,697,783,776,786,698,698,777,710,787,712,702,719,717,717,717,790,790,781,789,705,791,789,791,781,792,794,782,720,707,794,785,796,786,797,787,798,788,799,714,714,788,727,719,733,793,734,794,736,796,737,737,801,740,740,798,742,799,744,800,728,737,739,761,761,802,762,768,768,804,769,769,805,803,807,765,765,803,774,767,780,780,809,806,810,807,811,784,784,808,776,780,792,810,795,811,785],\"j\":[1,3,1,1,0,7,4,8,9,9,9,10,11,11,13,2,12,15,17,19,19,19,11,11,14,21,21,15,14,23,23,25,17,17,28,26,9,29,29,10,9,8,22,22,32,31,24,24,34,35,26,28,37,35,38,37,31,38,30,40,40,41,42,42,42,43,43,44,11,12,47,13,15,15,49,49,18,50,11,19,19,45,48,15,21,53,25,25,57,58,49,49,55,59,57,57,34,62,62,36,63,63,40,40,41,41,66,67,60,62,42,69,69,43,42,70,43,43,44,73,72,73,74,74,74,75,75,76,46,77,49,50,80,51,51,80,46,52,52,77,82,82,83,54,53,84,86,86,49,58,58,78,85,55,90,59,61,61,92,93,59,90,61,95,91,68,96,96,72,72,73,99,98,99,100,102,101,100,94,75,74,76,75,105,105,106,96,106,107,107,107,108,108,109,79,111,111,112,112,113,113,113,86,115,115,115,88,116,117,110,111,111,112,112,113,113,120,120,90,90,123,86,91,114,115,115,127,122,93,90,95,95,130,128,131,98,98,126,95,133,129,102,134,97,130,130,130,130,133,133,107,139,139,108,107,109,108,105,134,134,135,142,134,144,145,146,137,139,148,146,149,148,142,149,141,151,152,152,152,153,153,154,116,156,156,157,157,158,158,159,159,159,123,161,161,161,125,162,163,155,156,156,157,157,158,167,158,159,166,159,129,129,170,161,161,161,167,171,172,129,133,168,171,174,138,138,176,136,176,178,144,179,138,181,175,147,182,143,176,176,178,183,176,185,181,181,152,188,188,153,152,154,153,150,182,182,183,191,182,193,187,187,196,194,189,196,188,198,198,199,199,200,201,201,201,202,162,204,204,205,205,206,206,206,169,203,207,208,203,203,204,204,205,205,211,211,172,207,212,213,207,207,216,209,209,209,210,210,211,171,219,174,175,175,222,213,213,213,214,214,219,174,179,179,226,175,181,220,228,179,228,230,185,231,233,234,226,226,235,184,228,228,237,236,230,230,233,233,195,187,241,199,198,200,199,192,235,235,245,244,246,245,237,237,249,248,239,251,201,252,252,202,201,197,241,241,255,254,256,255,257,256,258,257,246,258,245,260,261,261,261,262,262,263,263,264,264,265,265,266,266,267,267,268,268,269,215,271,271,272,272,272,221,274,274,270,274,275,270,270,271,271,278,272,277,278,226,273,279,280,273,273,274,274,275,275,276,276,277,277,286,278,285,286,233,279,287,288,279,279,291,281,281,281,282,293,294,294,296,284,284,297,298,298,285,285,299,299,240,240,302,288,288,288,289,289,293,294,297,306,307,307,307,307,308,308,240,250,250,300,259,312,307,247,311,313,249,315,308,262,261,263,262,264,263,265,264,266,265,267,266,268,267,269,268,324,324,325,311,325,326,327,314,316,329,327,330,329,331,330,332,331,333,332,334,333,323,334,322,336,337,338,327,329,330,338,329,341,341,342,342,343,343,344,344,345,346,346,290,348,348,348,295,349,351,353,353,355,355,357,301,359,359,347,359,360,347,347,362,348,361,349,362,363,364,349,363,364,365,365,365,366,366,367,308,369,369,358,369,370,358,358,359,359,374,361,361,361,362,362,363,377,378,378,379,364,378,379,315,315,382,369,369,369,370,370,371,371,372,372,378,386,386,379,378,379,326,315,315,388,381,389,386,387,387,386,393,395,395,396,389,397,337,398,398,339,399,342,341,343,342,401,343,343,404,404,345,345,405,405,405,406,406,407,407,408,346,409,346,410,409,410,410,411,411,412,414,416,418,420,420,422,422,424,424,426,426,428,428,430,430,431,413,432,413,434,432,435,437,436,417,439,351,439,439,352,353,440,441,353,442,423,443,425,425,443,444,355,445,425,446,445,447,446,448,447,449,448,434,451,449,452,453,454,436,439,365,456,456,366,365,458,441,366,442,457,459,460,460,459,459,357,460,445,446,461,445,464,446,447,466,464,467,466,451,467,449,469,373,471,471,472,472,472,473,473,473,475,456,457,477,475,478,477,461,480,478,481,464,479,480,481,481,484,466,467,467,467,381,382,489,383,383,489,384,490,373,385,385,493,494,494,471,471,495,495,496,496,496,498,477,478,500,498,480,480,502,502,388,503,390,504,505,487,507,507,506,506,494,494,510,510,511,512,498,500,500,500,393,516,516,503,516,517,504,518,520,520,519,519,522,509,506,509,509,510,523,524,525,514,512,527,527,515,527,393,528,405,516,529,406,530,517,531,407,532,518,534,536,407,537,537,538,538,411,538,410,519,519,522,539,539,539,540,540,541,541,542,542,543,545,547,547,549,549,551,414,552,554,419,555,556,544,420,420,420,422,422,424,551,557,557,426,557,428,558,414,430,430,552,560,560,435,435,554,437,563,438,565,567,564,442,443,443,570,571,571,572,570,572,450,435,435,575,437,578,563,455,564,579,564,564,582,567,581,570,582,583,583,572,570,584,465,585,574,586,584,586,575,576,576,575,590,590,473,591,580,593,591,474,476,592,595,579,581,581,582,582,599,583,598,465,584,482,599,584,584,600,485,601,588,601,604,589,486,605,605,607,488,609,609,610,610,611,611,611,612,476,595,496,613,614,615,596,612,593,597,614,497,613,619,617,618,499,598,497,597,597,497,620,621,621,621,621,502,600,622,502,623,486,624,623,625,606,624,625,488,505,505,627,628,628,609,609,629,611,610,611,630,630,630,631,511,632,633,620,511,621,513,634,635,635,634,501,636,514,638,637,623,640,641,640,518,504,643,643,642,642,645,629,628,629,646,646,526,636,647,646,524,648,648,637,527,638,648,649,651,649,531,637,653,652,533,640,518,653,536,654,537,655,536,642,642,645,539,647,647,648,648,650,650,651,651,653,657,545,546,659,658,661,661,662,662,662,663,663,656,556,556,665,656,660,661,661,662,662,667,667,668,558,557,671,671,672,672,673,673,673,563,563,675,675,565,565,678,678,680,678,678,681,669,571,670,679,682,683,683,682,574,682,684,669,671,671,672,672,687,687,578,674,563,689,691,675,675,675,693,693,693,574,684,585,695,696,697,685,694,683,695,587,698,686,696,686,699,687,699,699,590,700,590,591,701,580,700,691,702,592,594,594,592,703,703,692,691,705,707,706,695,709,695,711,709,699,710,588,711,601,714,713,712,699,601,589,602,603,715,716,716,716,717,717,718,596,717,704,719,614,615,615,614,705,720,720,616,720,706,721,618,707,723,722,724,723,725,724,726,715,622,727,725,714,713,713,714,728,729,729,730,716,729,731,731,731,732,732,733,733,734,734,620,735,632,736,737,634,738,722,724,738,723,741,740,638,724,639,743,725,744,622,745,639,741,741,639,744,745,745,729,729,747,731,730,731,646,737,748,636,646,748,649,741,741,745,745,746,746,747,657,749,663,749,750,751,752,749,751,753,753,754,754,755,755,755,674,674,750,750,751,751,758,753,752,759,677,760,753,761,763,759,762,680,755,678,754,754,678,762,762,755,670,764,688,756,766,757,768,758,758,692,769,768,692,770,759,771,693,772,772,773,764,693,765,772,774,775,775,774,776,775,774,764,694,685,697,696,777,777,700,778,702,779,767,703,779,703,770,770,782,781,784,707,775,782,708,776,783,777,787,777,786,788,788,788,717,789,719,790,780,791,781,790,705,789,720,793,793,720,794,792,721,781,721,785,794,783,783,783,786,786,787,787,800,788,799,800,732,789,789,793,793,794,794,796,801,797,801,798,797,798,798,799,799,800,748,801,760,803,803,803,767,805,805,802,805,806,802,802,808,803,807,808,779,804,809,805,805,805,806,806,811,808,807,808,790,809,809,810,810,811],\"k\":[2,0,0,4,3,0,0,7,5,4,7,7,12,2,14,13,13,14,18,20,16,11,5,1,6,22,8,21,15,24,22,24,16,26,16,16,29,20,28,30,30,22,30,31,22,22,25,33,27,36,35,35,28,28,29,29,40,31,31,31,32,32,36,35,37,37,38,38,45,45,12,12,13,47,50,18,51,51,19,52,51,52,53,53,54,54,23,54,58,49,27,17,33,33,56,60,62,56,60,62,39,40,65,41,33,59,61,68,67,67,69,62,67,70,70,43,72,44,39,44,44,63,68,67,69,69,70,70,77,48,78,78,50,50,81,81,52,82,81,82,53,83,85,83,83,55,87,58,58,88,87,88,89,84,55,55,86,91,64,92,93,93,66,61,61,94,71,72,98,73,64,73,73,92,95,100,100,94,68,103,103,104,104,104,76,105,106,96,102,101,103,103,104,104,110,81,80,82,81,83,82,85,114,88,87,116,116,117,110,117,117,118,118,119,119,120,89,121,89,121,124,123,123,124,124,125,128,127,122,122,123,129,97,131,98,99,131,99,100,95,95,132,105,130,134,135,131,136,132,137,139,132,137,140,140,141,141,134,141,142,144,135,135,135,138,147,146,146,139,139,140,140,151,142,142,142,147,146,148,148,149,149,155,118,117,119,118,120,119,121,120,122,160,125,124,162,162,163,155,163,163,164,164,165,165,128,167,158,167,127,168,160,161,168,160,170,131,131,173,172,172,173,136,136,172,175,143,174,136,176,136,178,145,138,138,180,150,176,182,183,185,178,178,178,180,186,188,180,186,189,189,190,190,182,190,191,193,183,183,183,186,194,186,186,198,189,189,189,190,190,191,191,195,194,196,196,203,164,163,165,164,166,165,167,207,162,203,203,209,208,210,209,211,210,171,167,212,169,207,207,214,213,209,214,208,216,216,217,217,211,171,171,220,212,213,220,212,222,222,223,224,224,177,224,227,226,226,227,184,225,179,228,179,230,234,226,187,181,192,228,235,236,228,228,231,238,232,239,239,239,197,242,242,243,243,235,243,244,235,235,236,236,238,247,250,250,248,248,252,239,251,253,253,241,253,254,241,241,242,242,243,243,244,244,260,246,246,246,249,248,251,251,252,252,253,253,254,254,255,255,256,256,257,257,258,258,270,217,216,218,217,219,273,223,222,215,270,270,276,275,277,276,224,278,278,225,279,221,273,273,281,280,282,281,283,282,284,283,285,284,229,286,286,231,287,226,279,279,289,288,281,289,280,291,291,294,282,283,284,294,283,298,284,285,299,298,238,231,300,287,288,300,287,302,302,303,304,304,305,307,298,299,247,238,309,250,250,310,309,310,260,307,312,307,260,260,261,249,249,316,316,317,317,318,318,319,319,320,320,321,321,322,322,323,323,323,269,324,325,311,315,328,327,327,316,316,317,317,318,318,319,319,320,320,321,321,336,323,323,323,328,339,338,338,341,330,330,330,331,331,332,332,333,333,334,334,339,338,347,292,291,293,349,297,352,354,350,356,354,356,358,303,302,290,347,347,361,360,304,362,362,295,349,349,305,364,364,306,351,350,354,354,356,356,368,310,309,301,358,358,371,370,372,371,361,372,360,374,374,375,375,378,363,364,312,379,379,313,380,368,369,380,368,382,382,383,383,384,384,385,377,377,324,386,386,325,389,326,388,390,380,326,387,335,391,336,394,396,392,395,396,396,398,389,397,398,340,400,400,401,401,343,403,344,344,403,335,391,393,392,396,396,397,397,398,398,408,408,340,346,346,399,400,400,401,401,415,413,419,421,417,423,421,425,423,427,425,429,427,431,429,430,431,431,416,413,413,434,438,438,436,436,439,421,417,421,421,355,440,442,353,443,423,440,355,440,443,445,355,427,427,427,429,429,431,431,432,432,435,434,434,451,437,455,454,454,456,439,454,457,457,366,366,441,457,442,458,457,458,441,444,460,357,461,463,446,446,465,464,464,447,447,448,448,469,451,451,451,470,375,374,376,375,377,455,454,456,476,475,475,457,457,460,460,462,461,461,482,481,465,465,464,466,485,484,484,468,486,487,487,382,382,490,490,491,491,385,492,491,494,470,471,495,494,387,377,476,475,477,499,498,498,478,478,482,501,485,484,503,504,504,505,487,505,508,506,494,509,510,509,391,387,499,513,512,512,501,514,515,395,394,388,503,503,503,503,521,519,506,522,402,522,522,403,404,404,513,523,524,526,526,528,525,527,515,528,393,530,529,516,532,405,531,517,534,406,517,536,534,408,408,536,409,537,519,411,411,411,412,412,524,525,528,528,530,530,532,532,534,534,546,548,544,550,548,550,552,416,555,418,419,419,420,556,419,544,544,548,548,557,424,426,558,558,559,559,430,560,559,560,433,561,433,561,553,554,554,553,566,568,568,443,568,569,571,443,569,573,573,574,435,576,562,452,453,437,437,577,566,566,581,579,459,582,582,444,570,570,462,583,583,585,585,574,572,587,587,588,576,468,589,469,578,577,590,590,592,594,474,591,593,596,579,595,597,595,598,597,479,599,599,479,465,481,481,481,483,601,601,588,586,600,589,604,468,606,604,606,608,490,489,491,490,492,491,493,594,595,476,613,614,613,596,615,593,595,614,597,617,496,616,619,499,618,497,598,619,616,619,621,598,599,501,482,600,622,600,623,502,604,604,604,505,625,606,606,505,626,625,628,608,609,629,628,508,629,629,507,615,613,617,617,631,631,632,633,621,511,634,513,633,632,633,621,501,501,639,639,637,637,623,623,641,641,644,642,628,645,521,645,645,520,635,513,514,647,636,524,646,527,526,529,638,527,649,648,652,650,637,531,654,651,640,533,533,535,654,536,642,537,537,537,538,538,647,539,540,540,541,541,542,542,543,543,658,656,545,660,660,547,546,549,547,551,664,555,556,664,555,660,545,665,665,666,666,667,557,668,670,668,668,559,558,560,559,561,560,562,663,674,566,565,677,568,568,677,678,571,569,571,571,669,679,670,681,679,681,669,683,685,669,684,686,684,687,686,576,562,689,578,578,690,580,580,676,692,680,679,683,684,574,695,696,695,685,697,683,684,585,698,587,696,686,587,686,686,589,576,689,690,700,700,700,700,580,702,691,701,702,701,580,704,596,703,692,704,708,708,706,706,698,695,695,710,699,711,588,713,715,712,713,713,589,601,603,602,602,605,603,607,702,594,717,717,596,719,704,718,719,718,596,720,614,616,721,721,722,706,721,706,706,706,709,709,711,711,602,726,727,622,714,725,726,602,726,729,715,716,625,730,730,626,625,627,719,615,630,732,631,733,722,632,735,734,736,738,634,723,740,724,724,742,638,740,639,724,744,744,725,745,622,743,745,743,725,745,729,746,747,746,644,747,747,643,735,735,737,738,738,738,741,649,652,652,654,654,655,655,749,659,750,657,749,749,665,752,752,666,665,667,666,668,667,670,756,750,757,756,758,757,676,758,758,677,759,753,760,754,761,763,680,762,678,755,763,761,763,765,764,762,755,685,756,688,756,756,758,766,757,676,692,769,769,769,770,770,772,759,771,693,693,764,772,765,773,772,773,764,777,774,775,775,685,694,696,697,697,698,766,779,779,767,766,692,778,770,781,771,771,771,785,775,707,772,775,784,777,783,710,787,787,712,710,714,778,790,790,780,778,792,791,705,790,720,789,791,792,791,795,793,781,721,782,795,783,794,797,796,798,797,799,798,727,800,800,728,789,732,733,733,734,734,736,736,796,796,739,801,801,740,742,742,744,744,801,748,802,762,761,765,804,769,768,760,802,802,807,806,774,808,808,776,804,779,804,804,810,809,811,810,785,811,811,784,809,790,792,792,795,795],\"name\":\"Pancreas\",\"opacity\":0.5,\"x\":[61.0,60.0,61.0,62.0,61.0,60.0,63.0,63.0,64.0,61.0,63.0,60.0,61.0,63.0,63.0,64.0,57.0,56.0,57.0,59.0,59.0,65.0,65.0,67.0,67.0,68.0,57.0,56.0,59.0,61.0,63.0,65.0,67.0,68.0,57.0,59.0,58.0,61.0,63.0,64.0,65.0,67.0,59.0,61.0,63.0,61.0,62.0,63.0,64.0,56.0,57.0,59.0,61.0,65.0,67.0,68.0,55.0,54.0,55.0,68.0,55.0,54.0,57.0,65.0,66.0,67.0,55.0,57.0,56.0,59.0,61.0,62.0,63.0,65.0,57.0,59.0,61.0,63.0,57.0,58.0,59.0,61.0,63.0,65.0,67.0,66.0,54.0,55.0,57.0,67.0,68.0,54.0,67.0,68.0,55.0,54.0,63.0,64.0,65.0,67.0,55.0,57.0,56.0,59.0,61.0,62.0,63.0,57.0,59.0,61.0,59.0,61.0,63.0,65.0,55.0,57.0,58.0,59.0,61.0,63.0,65.0,67.0,68.0,54.0,55.0,57.0,67.0,67.0,66.0,54.0,65.0,66.0,55.0,54.0,63.0,65.0,66.0,55.0,54.0,57.0,59.0,61.0,63.0,64.0,65.0,55.0,57.0,56.0,59.0,61.0,62.0,63.0,57.0,59.0,61.0,59.0,61.0,63.0,65.0,67.0,55.0,57.0,58.0,59.0,61.0,63.0,65.0,66.0,55.0,56.0,57.0,66.0,54.0,55.0,66.0,54.0,65.0,67.0,67.0,68.0,55.0,54.0,63.0,65.0,66.0,67.0,55.0,54.0,57.0,59.0,61.0,63.0,64.0,65.0,55.0,54.0,57.0,58.0,59.0,61.0,63.0,55.0,57.0,59.0,61.0,63.0,65.0,57.0,59.0,61.0,63.0,65.0,55.0,57.0,59.0,60.0,61.0,63.0,65.0,66.0,55.0,56.0,57.0,59.0,67.0,68.0,54.0,55.0,67.0,69.0,69.0,70.0,53.0,52.0,53.0,65.0,67.0,69.0,70.0,53.0,52.0,59.0,61.0,63.0,65.0,67.0,69.0,70.0,51.0,50.0,51.0,53.0,55.0,57.0,59.0,61.0,63.0,65.0,67.0,68.0,69.0,51.0,53.0,55.0,57.0,59.0,61.0,63.0,65.0,67.0,61.0,63.0,65.0,57.0,59.0,61.0,63.0,65.0,67.0,55.0,57.0,59.0,61.0,63.0,65.0,67.0,69.0,53.0,55.0,57.0,58.0,59.0,61.0,62.0,63.0,64.0,65.0,66.0,67.0,69.0,53.0,54.0,55.0,57.0,63.0,67.0,68.0,69.0,50.0,51.0,53.0,69.0,69.0,70.0,51.0,50.0,53.0,55.0,57.0,59.0,61.0,63.0,65.0,67.0,68.0,69.0,51.0,53.0,52.0,55.0,57.0,59.0,61.0,63.0,65.0,66.0,67.0,53.0,55.0,54.0,56.0,57.0,59.0,61.0,63.0,65.0,55.0,59.0,61.0,65.0,33.0,32.0,33.0,35.0,35.0,37.0,37.0,38.0,55.0,57.0,59.0,61.0,63.0,65.0,67.0,33.0,35.0,37.0,51.0,53.0,55.0,57.0,59.0,60.0,61.0,63.0,65.0,66.0,67.0,69.0,51.0,52.0,53.0,55.0,57.0,59.0,67.0,66.0,50.0,51.0,51.0,66.0,47.0,46.0,47.0,49.0,49.0,51.0,53.0,57.0,59.0,61.0,62.0,63.0,65.0,47.0,49.0,51.0,53.0,55.0,57.0,59.0,61.0,45.0,44.0,45.0,46.0,31.0,30.0,31.0,33.0,33.0,35.0,35.0,37.0,37.0,39.0,39.0,41.0,41.0,43.0,43.0,45.0,47.0,47.0,48.0,29.0,28.0,29.0,31.0,36.0,37.0,36.0,37.0,38.0,39.0,41.0,43.0,45.0,47.0,49.0,49.0,50.0,29.0,31.0,30.0,33.0,35.0,36.0,37.0,37.0,39.0,40.0,41.0,43.0,42.0,45.0,47.0,48.0,49.0,61.0,63.0,65.0,31.0,33.0,35.0,34.0,37.0,39.0,41.0,41.0,43.0,42.0,45.0,47.0,46.0,48.0,53.0,54.0,55.0,57.0,59.0,61.0,62.0,63.0,65.0,35.0,37.0,39.0,38.0,41.0,42.0,47.0,51.0,52.0,53.0,61.0,61.0,60.0,63.0,65.0,39.0,41.0,40.0,42.0,47.0,49.0,51.0,52.0,59.0,59.0,58.0,61.0,41.0,42.0,43.0,43.0,45.0,45.0,47.0,47.0,49.0,49.0,51.0,51.0,52.0,53.0,55.0,57.0,43.0,45.0,47.0,49.0,51.0,33.0,32.0,33.0,35.0,35.0,37.0,37.0,38.0,45.0,29.0,28.0,29.0,31.0,39.0,41.0,43.0,45.0,47.0,48.0,28.0,33.0,33.0,32.0,35.0,35.0,37.0,39.0,39.0,41.0,41.0,42.0,49.0,48.0,29.0,28.0,33.0,32.0,35.0,37.0,39.0,43.0,43.0,45.0,45.0,46.0,48.0,29.0,31.0,33.0,33.0,32.0,35.0,34.0,37.0,39.0,41.0,47.0,47.0,48.0,49.0,49.0,51.0,51.0,52.0,55.0,57.0,59.0,61.0,33.0,35.0,35.0,34.0,37.0,37.0,39.0,38.0,40.0,41.0,48.0,49.0,51.0,53.0,55.0,56.0,57.0,59.0,35.0,37.0,39.0,40.0,41.0,40.0,42.0,47.0,46.0,47.0,49.0,51.0,55.0,55.0,54.0,57.0,41.0,43.0,45.0,47.0,47.0,49.0,49.0,51.0,51.0,53.0,31.0,30.0,31.0,32.0,33.0,35.0,37.0,28.0,29.0,33.0,35.0,37.0,39.0,41.0,40.0,43.0,45.0,47.0,28.0,33.0,34.0,35.0,37.0,39.0,38.0,40.0,41.0,41.0,43.0,42.0,45.0,47.0,29.0,29.0,30.0,33.0,34.0,39.0,41.0,43.0,43.0,42.0,44.0,47.0,31.0,32.0,32.0,35.0,35.0,36.0,41.0,40.0,41.0,43.0,45.0,45.0,47.0,47.0,48.0,49.0,51.0,33.0,34.0,34.0,37.0,39.0,41.0,43.0,45.0,47.0,48.0,49.0,50.0,51.0,53.0,55.0,35.0,37.0,39.0,41.0,41.0,42.0,43.0,44.0,45.0,47.0,47.0,48.0,49.0,49.0,51.0,53.0,43.0,31.0,29.0,31.0,33.0,35.0,37.0,39.0,29.0,31.0,33.0,37.0,36.0,37.0,39.0,38.0,41.0,40.0,31.0,32.0,33.0,35.0,35.0,37.0,39.0,40.0,41.0,41.0,42.0,43.0,33.0,33.0,34.0,37.0,39.0,41.0,41.0,40.0,43.0,45.0,47.0,35.0,35.0,36.0,37.0,37.0,39.0,39.0,41.0,43.0,45.0,47.0,49.0,43.0,37.0,39.0,33.0,35.0,37.0,39.0,41.0,35.0,37.0,39.0],\"y\":[37.0,37.0,36.0,37.0,39.0,39.0,38.0,39.0,39.0,40.0,40.0,37.0,36.0,36.0,37.0,37.0,39.0,39.0,38.0,38.0,39.0,38.0,39.0,38.0,39.0,39.0,41.0,41.0,41.0,41.0,41.0,41.0,41.0,41.0,42.0,43.0,43.0,43.0,43.0,43.0,42.0,42.0,44.0,44.0,44.0,37.0,37.0,36.0,37.0,39.0,38.0,38.0,38.0,38.0,38.0,39.0,41.0,41.0,40.0,41.0,43.0,43.0,43.0,43.0,43.0,42.0,44.0,45.0,45.0,45.0,45.0,45.0,44.0,44.0,46.0,46.0,46.0,37.0,39.0,39.0,38.0,38.0,38.0,38.0,39.0,39.0,41.0,40.0,40.0,40.0,41.0,43.0,43.0,43.0,45.0,45.0,45.0,45.0,44.0,44.0,46.0,47.0,47.0,47.0,47.0,47.0,46.0,48.0,48.0,48.0,39.0,39.0,39.0,39.0,41.0,41.0,41.0,40.0,40.0,40.0,40.0,40.0,41.0,43.0,42.0,42.0,43.0,42.0,43.0,45.0,45.0,45.0,47.0,47.0,47.0,47.0,47.0,49.0,49.0,49.0,49.0,49.0,49.0,49.0,48.0,50.0,51.0,51.0,51.0,51.0,51.0,50.0,52.0,52.0,52.0,41.0,41.0,41.0,41.0,41.0,43.0,43.0,43.0,42.0,42.0,42.0,42.0,43.0,45.0,45.0,44.0,45.0,47.0,46.0,47.0,49.0,49.0,48.0,49.0,49.0,51.0,51.0,51.0,51.0,51.0,50.0,53.0,53.0,53.0,53.0,53.0,53.0,53.0,52.0,55.0,55.0,55.0,55.0,54.0,54.0,54.0,56.0,56.0,43.0,43.0,43.0,43.0,45.0,45.0,45.0,45.0,45.0,47.0,47.0,47.0,47.0,46.0,46.0,46.0,47.0,49.0,49.0,48.0,48.0,48.0,49.0,51.0,50.0,51.0,50.0,51.0,51.0,53.0,53.0,52.0,53.0,53.0,53.0,53.0,55.0,55.0,55.0,55.0,55.0,55.0,55.0,55.0,55.0,57.0,57.0,56.0,57.0,57.0,57.0,57.0,57.0,57.0,57.0,57.0,57.0,56.0,58.0,58.0,58.0,58.0,58.0,58.0,58.0,58.0,58.0,47.0,47.0,47.0,49.0,49.0,49.0,49.0,49.0,49.0,51.0,51.0,51.0,51.0,51.0,51.0,51.0,51.0,53.0,53.0,53.0,53.0,52.0,52.0,53.0,53.0,53.0,52.0,53.0,53.0,53.0,55.0,55.0,54.0,54.0,54.0,54.0,55.0,55.0,57.0,56.0,56.0,57.0,56.0,57.0,59.0,59.0,59.0,59.0,59.0,59.0,59.0,59.0,59.0,59.0,59.0,58.0,60.0,61.0,61.0,61.0,61.0,61.0,61.0,61.0,61.0,61.0,60.0,62.0,63.0,63.0,63.0,62.0,62.0,62.0,62.0,62.0,64.0,53.0,53.0,53.0,55.0,55.0,54.0,54.0,55.0,54.0,55.0,55.0,55.0,55.0,55.0,55.0,55.0,55.0,55.0,56.0,56.0,56.0,57.0,57.0,57.0,57.0,57.0,57.0,56.0,56.0,56.0,57.0,57.0,57.0,59.0,59.0,58.0,58.0,58.0,58.0,59.0,59.0,61.0,61.0,60.0,61.0,63.0,63.0,62.0,62.0,63.0,63.0,63.0,63.0,63.0,63.0,63.0,62.0,62.0,64.0,64.0,64.0,64.0,64.0,64.0,64.0,64.0,51.0,51.0,50.0,51.0,53.0,53.0,52.0,52.0,53.0,52.0,53.0,52.0,53.0,52.0,53.0,52.0,53.0,52.0,53.0,53.0,52.0,53.0,53.0,55.0,55.0,54.0,55.0,54.0,55.0,55.0,54.0,55.0,55.0,55.0,55.0,55.0,55.0,54.0,55.0,55.0,56.0,57.0,57.0,57.0,57.0,56.0,56.0,57.0,57.0,57.0,56.0,57.0,57.0,57.0,57.0,57.0,56.0,57.0,57.0,57.0,58.0,58.0,59.0,59.0,59.0,59.0,58.0,59.0,58.0,59.0,58.0,59.0,59.0,59.0,59.0,59.0,58.0,58.0,58.0,58.0,59.0,59.0,59.0,60.0,60.0,61.0,61.0,61.0,61.0,60.0,61.0,61.0,60.0,61.0,60.0,61.0,61.0,61.0,62.0,63.0,63.0,63.0,63.0,63.0,63.0,63.0,63.0,62.0,63.0,63.0,64.0,65.0,65.0,64.0,64.0,65.0,64.0,65.0,64.0,65.0,64.0,65.0,65.0,64.0,64.0,64.0,66.0,66.0,66.0,66.0,66.0,51.0,51.0,50.0,50.0,51.0,50.0,51.0,51.0,51.0,53.0,53.0,52.0,52.0,52.0,52.0,52.0,52.0,52.0,53.0,55.0,55.0,54.0,55.0,55.0,54.0,54.0,55.0,54.0,55.0,54.0,55.0,55.0,55.0,57.0,57.0,57.0,57.0,57.0,57.0,57.0,57.0,56.0,57.0,56.0,57.0,57.0,58.0,58.0,58.0,59.0,59.0,59.0,59.0,59.0,59.0,59.0,59.0,58.0,59.0,58.0,59.0,58.0,59.0,59.0,59.0,59.0,59.0,59.0,60.0,61.0,60.0,61.0,60.0,61.0,60.0,60.0,61.0,61.0,61.0,61.0,61.0,60.0,60.0,61.0,61.0,61.0,62.0,62.0,62.0,62.0,62.0,63.0,63.0,63.0,63.0,62.0,63.0,63.0,63.0,62.0,63.0,63.0,64.0,65.0,65.0,64.0,65.0,65.0,64.0,65.0,64.0,64.0,51.0,51.0,50.0,51.0,51.0,51.0,51.0,53.0,52.0,52.0,52.0,52.0,52.0,53.0,53.0,53.0,53.0,53.0,55.0,55.0,55.0,54.0,54.0,55.0,55.0,54.0,54.0,55.0,55.0,55.0,55.0,55.0,56.0,57.0,57.0,57.0,57.0,56.0,56.0,57.0,56.0,57.0,57.0,57.0,58.0,58.0,59.0,58.0,59.0,59.0,59.0,59.0,58.0,59.0,58.0,59.0,58.0,59.0,59.0,59.0,59.0,60.0,60.0,61.0,60.0,60.0,61.0,61.0,61.0,61.0,60.0,60.0,61.0,61.0,61.0,61.0,62.0,62.0,62.0,63.0,62.0,63.0,63.0,63.0,62.0,63.0,62.0,62.0,62.0,63.0,63.0,63.0,64.0,51.0,53.0,53.0,53.0,53.0,53.0,53.0,55.0,55.0,55.0,55.0,55.0,54.0,54.0,54.0,55.0,55.0,57.0,57.0,56.0,56.0,57.0,57.0,57.0,56.0,56.0,57.0,57.0,57.0,59.0,58.0,59.0,59.0,59.0,59.0,58.0,59.0,59.0,59.0,59.0,61.0,60.0,60.0,60.0,61.0,61.0,60.0,61.0,61.0,61.0,61.0,61.0,63.0,55.0,55.0,57.0,57.0,57.0,57.0,57.0,59.0,59.0,59.0],\"z\":[12.0,13.0,13.0,13.0,12.0,13.0,13.0,12.0,13.0,13.0,13.0,15.0,15.0,15.0,14.0,15.0,14.0,15.0,15.0,15.0,14.0,15.0,14.0,15.0,14.0,15.0,14.0,15.0,14.0,14.0,14.0,14.0,14.0,15.0,15.0,14.0,15.0,14.0,14.0,15.0,15.0,15.0,15.0,15.0,15.0,16.0,17.0,17.0,17.0,17.0,17.0,17.0,17.0,17.0,17.0,17.0,16.0,17.0,17.0,17.0,16.0,17.0,16.0,16.0,17.0,17.0,17.0,16.0,17.0,16.0,16.0,17.0,17.0,17.0,17.0,17.0,17.0,18.0,18.0,19.0,19.0,19.0,19.0,19.0,18.0,19.0,19.0,19.0,19.0,19.0,19.0,19.0,18.0,19.0,18.0,19.0,18.0,19.0,19.0,19.0,19.0,18.0,19.0,18.0,18.0,19.0,19.0,19.0,19.0,19.0,20.0,20.0,20.0,20.0,20.0,20.0,21.0,21.0,21.0,21.0,21.0,21.0,21.0,21.0,21.0,21.0,20.0,21.0,21.0,21.0,20.0,21.0,20.0,21.0,20.0,20.0,21.0,20.0,21.0,20.0,20.0,20.0,20.0,21.0,21.0,21.0,20.0,21.0,20.0,20.0,21.0,21.0,21.0,21.0,21.0,22.0,22.0,22.0,22.0,22.0,22.0,22.0,23.0,23.0,23.0,23.0,23.0,23.0,22.0,23.0,23.0,23.0,23.0,23.0,23.0,23.0,22.0,23.0,22.0,23.0,22.0,23.0,22.0,22.0,23.0,23.0,22.0,23.0,22.0,22.0,22.0,22.0,23.0,23.0,22.0,23.0,22.0,23.0,23.0,23.0,23.0,23.0,23.0,24.0,24.0,24.0,24.0,24.0,24.0,24.0,24.0,24.0,24.0,24.0,24.0,25.0,25.0,25.0,25.0,25.0,24.0,25.0,25.0,25.0,25.0,25.0,25.0,25.0,24.0,25.0,24.0,25.0,24.0,25.0,25.0,24.0,24.0,24.0,25.0,24.0,25.0,24.0,24.0,24.0,24.0,24.0,24.0,25.0,24.0,25.0,25.0,24.0,24.0,24.0,24.0,24.0,24.0,24.0,24.0,25.0,25.0,25.0,25.0,25.0,25.0,25.0,25.0,25.0,25.0,25.0,26.0,26.0,26.0,26.0,26.0,26.0,26.0,26.0,26.0,26.0,26.0,26.0,26.0,26.0,26.0,26.0,26.0,26.0,26.0,26.0,27.0,27.0,27.0,27.0,26.0,27.0,27.0,27.0,26.0,26.0,26.0,27.0,27.0,27.0,27.0,27.0,27.0,26.0,27.0,27.0,27.0,26.0,27.0,27.0,26.0,27.0,26.0,26.0,26.0,26.0,26.0,26.0,26.0,26.0,27.0,27.0,27.0,26.0,27.0,26.0,26.0,26.0,26.0,26.0,26.0,27.0,27.0,27.0,26.0,27.0,27.0,27.0,27.0,27.0,27.0,27.0,27.0,28.0,28.0,28.0,28.0,29.0,29.0,29.0,28.0,29.0,28.0,29.0,28.0,28.0,28.0,28.0,28.0,28.0,28.0,29.0,29.0,29.0,28.0,28.0,28.0,28.0,28.0,29.0,29.0,29.0,29.0,29.0,28.0,28.0,28.0,29.0,29.0,29.0,29.0,29.0,28.0,29.0,29.0,28.0,29.0,29.0,28.0,29.0,29.0,29.0,28.0,28.0,28.0,28.0,28.0,28.0,29.0,29.0,29.0,29.0,29.0,29.0,29.0,29.0,29.0,29.0,29.0,30.0,31.0,31.0,31.0,30.0,31.0,31.0,31.0,30.0,31.0,30.0,31.0,30.0,31.0,30.0,31.0,30.0,31.0,30.0,30.0,31.0,30.0,31.0,30.0,31.0,31.0,30.0,30.0,30.0,31.0,31.0,31.0,30.0,30.0,30.0,30.0,30.0,31.0,30.0,31.0,31.0,30.0,31.0,30.0,30.0,30.0,31.0,30.0,30.0,31.0,31.0,30.0,31.0,30.0,30.0,31.0,31.0,30.0,30.0,30.0,31.0,31.0,30.0,31.0,30.0,30.0,31.0,30.0,31.0,31.0,31.0,30.0,31.0,31.0,30.0,31.0,31.0,31.0,31.0,31.0,31.0,30.0,30.0,31.0,31.0,30.0,31.0,30.0,31.0,31.0,30.0,31.0,31.0,30.0,31.0,31.0,30.0,30.0,31.0,30.0,31.0,31.0,30.0,30.0,30.0,31.0,30.0,31.0,31.0,30.0,31.0,31.0,30.0,31.0,31.0,30.0,31.0,30.0,31.0,30.0,31.0,30.0,31.0,31.0,31.0,31.0,31.0,31.0,31.0,31.0,31.0,32.0,33.0,33.0,33.0,32.0,33.0,32.0,33.0,32.0,32.0,33.0,33.0,33.0,33.0,33.0,33.0,33.0,33.0,33.0,33.0,32.0,33.0,33.0,32.0,33.0,33.0,32.0,33.0,32.0,33.0,33.0,32.0,33.0,32.0,33.0,32.0,33.0,32.0,32.0,32.0,32.0,33.0,32.0,33.0,33.0,33.0,33.0,33.0,33.0,32.0,33.0,32.0,33.0,32.0,32.0,32.0,32.0,33.0,33.0,33.0,32.0,33.0,32.0,33.0,32.0,32.0,32.0,32.0,33.0,32.0,33.0,33.0,33.0,32.0,33.0,32.0,33.0,32.0,33.0,32.0,32.0,33.0,33.0,33.0,32.0,32.0,33.0,33.0,33.0,32.0,33.0,33.0,33.0,32.0,33.0,33.0,32.0,32.0,32.0,33.0,33.0,32.0,33.0,32.0,32.0,33.0,32.0,32.0,33.0,32.0,33.0,33.0,34.0,35.0,35.0,35.0,34.0,34.0,34.0,35.0,35.0,35.0,35.0,35.0,35.0,34.0,35.0,34.0,34.0,34.0,35.0,34.0,35.0,35.0,35.0,34.0,35.0,34.0,35.0,34.0,34.0,35.0,34.0,34.0,35.0,34.0,35.0,34.0,35.0,35.0,35.0,34.0,35.0,35.0,35.0,34.0,35.0,34.0,35.0,35.0,34.0,35.0,34.0,35.0,35.0,34.0,35.0,34.0,35.0,34.0,35.0,34.0,34.0,35.0,34.0,35.0,35.0,35.0,34.0,34.0,34.0,34.0,34.0,35.0,35.0,34.0,34.0,34.0,35.0,35.0,35.0,34.0,35.0,35.0,34.0,35.0,35.0,34.0,35.0,34.0,35.0,34.0,34.0,34.0,35.0,36.0,36.0,36.0,36.0,36.0,36.0,36.0,36.0,36.0,36.0,36.0,37.0,37.0,37.0,36.0,36.0,37.0,36.0,37.0,37.0,37.0,36.0,36.0,36.0,36.0,37.0,36.0,37.0,36.0,36.0,37.0,37.0,36.0,36.0,36.0,37.0,37.0,36.0,36.0,36.0,36.0,37.0,36.0,37.0,36.0,36.0,37.0,36.0,36.0,36.0,36.0,36.0,36.0,38.0,38.0,38.0,38.0,38.0,38.0,38.0,38.0,38.0,38.0],\"type\":\"mesh3d\"},{\"color\":\"rgb(255, 0, 0)\",\"i\":[0,2,0,3,5,7,5,5,5,5,11,11,12,13,16,17,14,18,19,19,20,20,19,22,21,23,26,27,18,28,20,29,22,30,24,31,32,31,26,28,34,29,35,30,36,31,37,32,38,38,40,42,42,41,3,3,2,45,44,46,49,50,42,51,1,1,42,4,4,52,7,7,47,8,7,7,7,55,54,56,49,59,59,49,52,62,53,63,6,6,53,8,64,13,57,15,13,13,13,65,60,62,69,63,70,70,70,63,10,64,15,66,66,66,73,21,74,23,71,76,76,77,78,73,73,74,75,82,25,75,27,33,34,33,80,80,84,36,81,37,82,32,40,86,86,87,43,41,89,89,44,44,89,46,85,39,93,92,89,91,95,96,54,54,54,54,96,56,50,61,59,59,59,100,102,97,97,96,98,106,58,58,98,65,61,99,99,68,70,69,72,72,72,109,105,111,106,112,107,113,67,107,72,77,77,114,112,115,79,79,113,73,77,84,115,80,87,87,116,88,116,86,117,119,90,90,117,94,120,95,93,101,101,122,120,123,103,103,121,97,101,109,123,104],\"j\":[1,3,4,4,6,8,9,10,11,8,5,13,13,15,10,10,18,16,14,20,18,21,21,23,23,25,17,17,28,26,29,28,30,29,31,30,24,24,33,33,33,34,34,35,35,36,36,37,39,41,41,2,41,43,44,2,43,46,46,48,39,39,51,49,4,52,52,3,45,45,6,53,53,54,54,48,47,56,56,58,59,60,49,51,62,60,63,62,9,64,64,55,9,12,13,65,65,58,57,67,68,68,68,69,69,71,63,64,17,10,66,21,73,67,74,75,75,75,76,71,17,17,79,79,78,78,74,74,82,82,83,83,84,84,35,84,34,78,78,81,81,82,39,40,87,41,41,87,88,44,43,91,91,91,50,50,86,93,90,89,91,95,95,91,48,98,98,98,59,99,61,100,93,99,103,103,102,102,96,96,107,98,106,107,68,108,68,69,109,109,110,102,109,102,102,102,105,105,106,106,113,113,76,110,114,111,111,111,115,113,112,113,83,114,114,115,86,117,117,117,93,93,116,116,120,117,119,121,121,121,100,118,122,119,119,119,123,121,120,121,108,122,122,123],\"k\":[2,0,1,0,7,5,6,9,10,12,12,14,11,14,11,16,11,11,15,14,14,22,20,24,22,24,16,26,16,16,18,18,20,20,22,22,25,32,27,26,28,28,29,29,30,30,31,31,40,42,38,1,2,2,45,44,44,47,45,47,38,49,38,38,52,42,51,45,52,53,53,47,45,55,8,54,48,57,55,57,50,61,60,60,51,51,52,52,64,53,63,12,10,55,55,66,15,65,58,66,61,60,62,62,63,72,71,71,71,71,19,19,21,73,21,23,21,25,72,17,77,27,80,78,74,81,82,81,32,25,77,27,33,83,78,35,35,35,36,36,37,37,85,85,40,40,88,88,90,88,88,46,44,48,92,85,85,85,94,94,94,97,96,95,91,56,54,58,92,100,100,93,92,101,104,102,96,105,106,105,65,107,107,67,99,101,108,108,69,108,102,109,70,104,111,110,112,111,113,112,73,67,110,76,110,110,115,114,80,115,115,79,114,83,84,84,116,88,87,90,118,116,119,118,94,120,120,95,94,97,118,100,118,118,123,122,104,123,123,103,122,108,109,109],\"name\":\"Tumor\",\"opacity\":0.5,\"x\":[37.0,36.0,37.0,38.0,37.0,41.0,40.0,41.0,42.0,41.0,42.0,43.0,43.0,45.0,45.0,46.0,43.0,42.0,45.0,47.0,47.0,49.0,49.0,51.0,51.0,52.0,43.0,42.0,45.0,47.0,49.0,51.0,52.0,43.0,45.0,47.0,49.0,51.0,33.0,32.0,33.0,35.0,35.0,37.0,39.0,39.0,41.0,41.0,42.0,33.0,32.0,35.0,37.0,39.0,43.0,43.0,45.0,45.0,46.0,33.0,35.0,34.0,37.0,39.0,41.0,47.0,47.0,48.0,35.0,37.0,39.0,41.0,40.0,48.0,49.0,51.0,41.0,42.0,47.0,47.0,46.0,49.0,51.0,43.0,45.0,33.0,34.0,35.0,37.0,39.0,38.0,41.0,33.0,34.0,39.0,41.0,43.0,42.0,45.0,35.0,35.0,36.0,41.0,41.0,40.0,43.0,45.0,47.0,37.0,39.0,41.0,43.0,45.0,47.0,43.0,45.0,35.0,37.0,35.0,37.0,39.0,41.0,37.0,39.0],\"y\":[55.0,55.0,54.0,55.0,56.0,57.0,57.0,56.0,57.0,58.0,59.0,59.0,58.0,58.0,59.0,59.0,61.0,61.0,61.0,60.0,61.0,60.0,61.0,60.0,61.0,61.0,63.0,63.0,63.0,63.0,63.0,63.0,63.0,64.0,64.0,64.0,64.0,64.0,55.0,55.0,54.0,54.0,55.0,54.0,54.0,55.0,54.0,55.0,55.0,57.0,57.0,57.0,57.0,57.0,56.0,57.0,56.0,57.0,57.0,58.0,59.0,59.0,59.0,59.0,59.0,58.0,59.0,59.0,60.0,60.0,60.0,61.0,61.0,61.0,61.0,61.0,62.0,63.0,63.0,62.0,63.0,63.0,63.0,64.0,64.0,55.0,55.0,54.0,54.0,55.0,55.0,55.0,57.0,57.0,56.0,56.0,57.0,57.0,57.0,59.0,58.0,59.0,59.0,58.0,59.0,59.0,59.0,59.0,60.0,60.0,61.0,61.0,61.0,61.0,63.0,63.0,55.0,55.0,57.0,57.0,57.0,57.0,59.0,59.0],\"z\":[30.0,31.0,31.0,31.0,31.0,30.0,31.0,31.0,31.0,31.0,31.0,30.0,31.0,31.0,30.0,31.0,30.0,31.0,30.0,31.0,30.0,31.0,30.0,31.0,30.0,31.0,30.0,31.0,30.0,30.0,30.0,30.0,31.0,31.0,31.0,31.0,31.0,31.0,32.0,33.0,33.0,33.0,32.0,33.0,33.0,32.0,33.0,32.0,33.0,32.0,33.0,32.0,32.0,32.0,33.0,32.0,33.0,32.0,33.0,33.0,32.0,33.0,32.0,32.0,32.0,33.0,32.0,33.0,33.0,33.0,33.0,32.0,33.0,33.0,32.0,32.0,33.0,33.0,32.0,33.0,33.0,32.0,32.0,33.0,33.0,34.0,35.0,35.0,35.0,34.0,35.0,34.0,34.0,35.0,35.0,35.0,34.0,35.0,34.0,34.0,35.0,35.0,34.0,35.0,35.0,34.0,34.0,34.0,35.0,35.0,34.0,34.0,34.0,34.0,34.0,34.0,36.0,36.0,36.0,36.0,36.0,36.0,36.0,36.0],\"type\":\"mesh3d\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"scene\":{\"aspectratio\":{\"x\":1,\"y\":1,\"z\":0.6666666666666666},\"camera\":{\"eye\":{\"x\":1.2,\"y\":1.2,\"z\":1.2}},\"xaxis\":{\"title\":{\"text\":\"X (RAS)\"}},\"yaxis\":{\"title\":{\"text\":\"Y (RAS)\"}},\"zaxis\":{\"title\":{\"text\":\"Z (RAS)\"}}},\"title\":{\"text\":\"3D 세분화 시각화\"}},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('04013e28-90cc-47c7-b43f-6d0cbc5c9496');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                            </script>        </div>\n","</body>\n","</html>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","--- 스크립트 종료 ---\n"]}],"source":["# -*- coding: utf-8 -*-\n","# ==============================================================================\n","# 췌장 세분화 추론 및 3D 시각화 스크립트\n","# ==============================================================================\n","import os\n","import torch\n","import monai\n","from monai.transforms import (\n","    Compose, LoadImaged, EnsureChannelFirstd, Orientationd,\n","    ScaleIntensityRanged, CropForegroundd, Resized, EnsureTyped,\n","    Activations, AsDiscrete\n",")\n","from monai.data import decollate_batch\n","from monai.networks.nets import UNet # MONAI_UNet으로 학습시킨 경우\n","# 또는 학습 스크립트에서 정의한 사용자 정의 클래스 임포트:\n","# from your_training_script import Custom3DUNet\n","import nibabel as nib\n","import numpy as np\n","import plotly.graph_objects as go\n","from skimage.measure import marching_cubes # 3D 메쉬 생성용\n","import gc\n","import time\n","import traceback\n","\n","# ==============================================================================\n","# 1. 설정 (경로 및 파라미터 수정 필요)\n","# ==============================================================================\n","\n","# --- 학습된 모델 ---\n","# !!! 중요: 올바른 모델 클래스 이름 선택 (Custom3DUNet 또는 MONAI_UNet) !!!\n","MODEL_DEFINITION = \"Custom3DUNet\" # 또는 \"MONAI_UNet\"\n","# !!! 저장된 최적 모델 가중치 파일 경로 !!!\n","MODEL_PATH = '/content/drive/MyDrive/2조/췌장암 영상/췌장암_로컬_수정/20250405-151938/checkpoints/best_model_20250405-151938.pth' # <<<--- 실제 경로로 수정하세요!\n","\n","# !!! 분석할 새로운 CT 영상 파일 경로 !!!\n","INPUT_CT_PATH = '/content/drive/MyDrive/2조/췌장암 영상/췌장암_로컬_수정/pancreas_025.nii' # <<<--- 실제 경로로 수정하세요!\n","\n","# --- 출력 ---\n","# 선택 사항: 예측된 세분화 마스크 저장 경로\n","OUTPUT_MASK_PATH = None # 저장하지 않으려면 None으로 설정\n","\n","# --- 모델 및 전처리 파라미터 (학습 시와 동일해야 함) ---\n","TARGET_SPATIAL_SHAPE = (64, 96, 96) # (D, H, W) - 학습 시와 동일하게 설정\n","HU_WINDOW = (-100, 240)             # 학습 시와 동일하게 설정\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","NUM_CLASSES = 3\n","\n","# --- 모델 아키텍처 파라미터 (Custom3DUNet 사용 시, 학습 시와 동일해야 함) ---\n","CUSTOM_UNET_FILTERS = [16, 32, 64, 128]\n","CUSTOM_UNET_DROPOUT = 0.15 # 학습 시 사용했다면 동일하게 설정\n","CUSTOM_UNET_ACTIVATION = 'leaky_relu' # 학습 시와 동일하게 설정\n","CUSTOM_UNET_LEAKY_SLOPE = 0.01     # 학습 시와 동일하게 설정\n","\n","# --- 모델 아키텍처 파라미터 (MONAI_UNet 사용 시, 학습 시와 동일해야 함) ---\n","MONAI_UNET_SPATIAL_DIMS = 3\n","MONAI_UNET_CHANNELS = (16, 32, 64, 128, 256) # 학습 시와 동일하게 설정\n","MONAI_UNET_STRIDES = (2, 2, 2, 2)          # 학습 시와 동일하게 설정\n","MONAI_UNET_NUM_RES_UNITS = 2              # 학습 시와 동일하게 설정\n","MONAI_UNET_DROPOUT = 0.15                 # 학습 시와 동일하게 설정\n","\n","# --- 시각화 파라미터 ---\n","VIS_STEP_SIZE = 2       # 메쉬 다운샘플링 (1=최대 해상도, 값이 클수록 빠르고 단순해짐)\n","PANCREAS_COLOR = 'rgb(107, 174, 214)' # 췌장 색상 (하늘색)\n","TUMOR_COLOR = 'rgb(255, 0, 0)'       # 종양 색상 (빨간색)\n","OPACITY = 0.5           # 메쉬 투명도\n","\n","# --- 레이블 정의 (1=췌장, 2=종양 가정) ---\n","LABEL_PANCREAS = 1\n","LABEL_TUMOR = 2\n","\n","# ==============================================================================\n","# 2. 필요한 클래스/함수 재정의 또는 임포트 (예: Custom3DUNet)\n","# ==============================================================================\n","\n","# Custom3DUNet을 사용했다면, 클래스 정의가 필요합니다.\n","# 학습 스크립트에서 임포트하거나 아래처럼 여기에 직접 정의합니다.\n","# (학습 스크립트의 Custom3DUNet 클래스 코드를 복사-붙여넣기 하세요)\n","import torch.nn as nn\n","import torch.nn.functional as F # forward에서 padding에 필요할 수 있음\n","\n","def get_activation(activation_type, negative_slope=0.01):\n","    if activation_type.lower() == 'relu': return nn.ReLU(inplace=True)\n","    elif activation_type.lower() == 'leaky_relu': return nn.LeakyReLU(negative_slope=negative_slope, inplace=True)\n","    else: raise ValueError(f\"지원하지 않는 활성화 함수 타입: {activation_type}\")\n","\n","class Custom3DUNet(nn.Module):\n","    # ... (이하 Custom3DUNet 클래스 정의는 학습 스크립트에서 복사) ...\n","    def __init__(self, in_channels=1, out_channels=3, filters=[16, 32, 64, 128], dropout_rate=0.1, activation='relu', leaky_slope=0.01):\n","        super().__init__()\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.filters = filters\n","        self.dropout_rate = dropout_rate\n","        self.activation = activation\n","        self.leaky_slope = leaky_slope\n","\n","        self.encoders = nn.ModuleList()\n","        self.pools = nn.ModuleList()\n","        self.decoders = nn.ModuleList()\n","        self.upconvs = nn.ModuleList()\n","\n","        def conv_block(ic, oc, act, ls, dr):\n","            layers = [\n","                nn.Conv3d(ic, oc, kernel_size=3, padding=1, bias=False), nn.BatchNorm3d(oc), get_activation(act, ls),\n","                nn.Conv3d(oc, oc, kernel_size=3, padding=1, bias=False), nn.BatchNorm3d(oc), get_activation(act, ls),\n","            ]\n","            if dr > 0.0: layers.append(nn.Dropout3d(dr))\n","            return nn.Sequential(*layers)\n","\n","        current_channels = in_channels\n","        for i, f in enumerate(filters):\n","            current_dropout = dropout_rate * (i / (len(filters) - 1)) if len(filters) > 1 and dropout_rate > 0 else 0.0\n","            encoder = conv_block(current_channels, f, self.activation, self.leaky_slope, current_dropout)\n","            pool = nn.MaxPool3d(kernel_size=2, stride=2)\n","            self.encoders.append(encoder)\n","            self.pools.append(pool)\n","            current_channels = f\n","\n","        bn_filters = filters[-1] * 2\n","        self.bottleneck = conv_block(current_channels, bn_filters, self.activation, self.leaky_slope, dropout_rate)\n","\n","        current_channels = bn_filters\n","        reversed_filters = list(reversed(filters))\n","        for i, f in enumerate(reversed_filters):\n","            upconv = nn.ConvTranspose3d(current_channels, f, kernel_size=2, stride=2)\n","            self.upconvs.append(upconv)\n","            concat_channels = f + f\n","            current_dropout = dropout_rate * ((len(filters) - 1 - i) / (len(filters) - 1)) if len(filters) > 1 and dropout_rate > 0 else 0.0\n","            decoder = conv_block(concat_channels, f, self.activation, self.leaky_slope, current_dropout)\n","            self.decoders.append(decoder)\n","            current_channels = f\n","\n","        self.output_conv = nn.Conv3d(current_channels, out_channels, kernel_size=1)\n","\n","    def forward(self, x):\n","        skips = []\n","        for i in range(len(self.filters)):\n","            x = self.encoders[i](x); skips.append(x); x = self.pools[i](x)\n","        x = self.bottleneck(x)\n","        skips = list(reversed(skips))\n","        for i in range(len(self.filters)):\n","            x = self.upconvs[i](x)\n","            skip_connection = skips[i]\n","            if x.shape[2:] != skip_connection.shape[2:]:\n","                # 간단한 중앙 크롭 (필요시 조정, MONAI 방식이 더 안정적)\n","                target_shape = x.shape[2:]\n","                skip_shape = skip_connection.shape[2:]\n","                try:\n","                    crop_slices = [slice((skip_shape[d] - target_shape[d]) // 2, (skip_shape[d] + target_shape[d]) // 2) for d in range(3)]\n","                    skip_connection = skip_connection[(slice(None), slice(None)) + tuple(crop_slices)]\n","                    # 홀수 차원으로 인한 오차 처리\n","                    if x.shape != skip_connection.shape: # 크롭 후 재확인\n","                         # 크롭으로 충분하지 않으면 패딩 시도 (또는 크기가 반대였던 경우)\n","                         padding = []\n","                         for d_idx in range(3):\n","                             pad_total = x.shape[d_idx+2] - skip_connection.shape[d_idx+2]\n","                             pad_before = pad_total // 2\n","                             pad_after = pad_total - pad_before\n","                             padding.extend([pad_before, pad_after]) # D, H, W 패딩\n","                         padding = padding[::-1] # F.pad 순서(W, H, D)로 뒤집기\n","                         if all(p >= 0 for p in padding):\n","                             skip_connection = F.pad(skip_connection, padding)\n","                             print(f\"  Skip connection을 다음 크기로 패딩: {skip_connection.shape}\")\n","                         else:\n","                              print(f\"오류: 크기 불일치 해결 불가. Upconv: {x.shape}, Skip (크롭 시도 후): {skip_connection.shape}\")\n","                except Exception as crop_e:\n","                    print(f\"  Skip connection 처리 중 오류: {crop_e}\")\n","                    # 필요에 따라 패딩 구현 또는 오류 발생\n","            x = torch.cat((skip_connection, x), dim=1)\n","            x = self.decoders[i](x)\n","        x = self.output_conv(x)\n","        return x\n","\n","\n","# ==============================================================================\n","# 3. 추론용 전처리 및 후처리 정의\n","# ==============================================================================\n","# 검증(validation) 시 사용했던 변환과 동일하게 사용 (단, 랜덤 증강 제외)\n","# LoadImaged가 사용할 키 정의\n","image_key = \"image\" # 입력 딕셔너리에서 예상되는 키\n","\n","inference_transforms = Compose(\n","    [\n","        # LoadImaged는 딕셔너리를 기대하므로 즉석에서 생성\n","        LoadImaged(keys=[image_key]),\n","        EnsureChannelFirstd(keys=[image_key]), # 채널 차원 추가 (C, D, H, W)\n","        Orientationd(keys=[image_key], axcodes=\"RAS\"), # 학습 시와 동일한 방향으로 정렬\n","        ScaleIntensityRanged(keys=[image_key], a_min=HU_WINDOW[0], a_max=HU_WINDOW[1], b_min=0.0, b_max=1.0, clip=True), # HU 값 스케일링\n","        # CropForegroundd: 학습 시 빈 공간 제거에 사용했다면 중요\n","        CropForegroundd(keys=[image_key], source_key=image_key, allow_smaller=True), # 크롭 후 목표 크기보다 작아지는 것 허용\n","        # 모델이 기대하는 크기로 리사이즈\n","        Resized(keys=[image_key], spatial_size=TARGET_SPATIAL_SHAPE, mode=\"area\"), # 이미지는 'area' 또는 'trilinear' 모드 사용\n","        EnsureTyped(keys=[image_key], dtype=torch.float32), # Tensor 타입 변환\n","    ]\n",")\n","\n","# 후처리: 활성화 함수 적용, 임계값 처리\n","post_pred_transform = Compose([\n","    Activations(softmax=True),\n","    AsDiscrete(argmax=True)\n","])\n","\n","\n","# ==============================================================================\n","# 4. 모델 로드 함수\n","# ==============================================================================\n","def load_segmentation_model(model_def_name, model_path, device, num_classes=3): # <<<--- num_classes 추가\n","    \"\"\"학습된 Multi-Class 세분화 모델을 로드합니다.\"\"\"\n","    print(f\"모델 로딩 중 '{model_def_name}' from: {model_path}\")\n","    if not os.path.exists(model_path):\n","        raise FileNotFoundError(f\"모델 체크포인트 파일을 찾을 수 없습니다: {model_path}\")\n","\n","    # 모델 아키텍처 정의\n","    if model_def_name == \"Custom3DUNet\":\n","        model = Custom3DUNet(\n","            in_channels=1, out_channels=num_classes,\n","            filters=CUSTOM_UNET_FILTERS,\n","            dropout_rate=CUSTOM_UNET_DROPOUT,\n","            activation=CUSTOM_UNET_ACTIVATION,\n","            leaky_slope=CUSTOM_UNET_LEAKY_SLOPE\n","        )\n","        print(f\"Custom3DUNet 로드 완료 (out_channels={num_classes})\")\n","    elif model_def_name == \"MONAI_UNet\":\n","        model = UNet(\n","            spatial_dims=MONAI_UNET_SPATIAL_DIMS,\n","            in_channels=1, out_channels=num_classes,\n","            channels=MONAI_UNET_CHANNELS,\n","            strides=MONAI_UNET_STRIDES,\n","            num_res_units=MONAI_UNET_NUM_RES_UNITS,\n","            act='PRELU', norm='BATCH', # 학습 시 설정과 일치\n","            dropout=MONAI_UNET_DROPOUT\n","        )\n","        print(f\"MONAI_UNet 로드 완료 (out_channels={num_classes})\")\n","    else:\n","        raise ValueError(f\"알 수 없는 모델 정의 이름: {model_def_name}\")\n","\n","    # 저장된 가중치 로드\n","    try:\n","        checkpoint = torch.load(model_path, map_location=device)\n","        # 저장 방식에 따라 state_dict 키 조정 필요\n","        if 'model_state_dict' in checkpoint:\n","            model.load_state_dict(checkpoint['model_state_dict'])\n","            print(f\"모델 상태 로드 완료 (epoch {checkpoint.get('epoch', 'N/A')})\")\n","        elif 'state_dict' in checkpoint:\n","             model.load_state_dict(checkpoint['state_dict'])\n","             print(\"모델 상태 로드 완료 (key 'state_dict')\")\n","        else:\n","             model.load_state_dict(checkpoint)\n","             print(\"모델 상태 로드 완료 (직접 로드)\")\n","\n","        model.to(device) # 모델을 지정된 장치(GPU 또는 CPU)로 이동\n","        model.eval()     # 모델을 평가(evaluation) 모드로 설정 (Dropout 등 비활성화)\n","        print(\"모델 로드 및 평가 모드 설정 완료.\")\n","        return model\n","    except Exception as e:\n","        print(f\"모델 체크포인트 로드 오류: {e}\")\n","        traceback.print_exc()\n","        raise\n","\n","# ==============================================================================\n","# 5. 추론 함수\n","# ==============================================================================\n","def run_inference(model, input_image_path, pre_transforms, post_transforms, device, out_key=\"pred\"):\n","    \"\"\"단일 이미지에 대해 전처리, 추론, 후처리를 수행합니다.\"\"\"\n","    print(f\"\\n추론 시작: {input_image_path}\")\n","    start_time = time.time()\n","\n","    # LoadImaged가 기대하는 딕셔너리 형식 생성\n","    input_data = {image_key: input_image_path}\n","\n","    # 전처리 적용\n","    try:\n","        print(\"전처리 변환 적용 중...\")\n","        preprocessed_data = pre_transforms(input_data)\n","        input_tensor = preprocessed_data[image_key] # shape: (C, D, H, W)\n","        print(f\"전처리 완료. 입력 텐서 shape: {input_tensor.shape}\")\n","\n","        # 배치 차원 추가 (B, C, D, H, W) 및 장치로 이동\n","        input_batch = input_tensor.unsqueeze(0).to(device)\n","\n","    except Exception as e:\n","        print(f\"전처리 중 오류 발생: {e}\")\n","        traceback.print_exc()\n","        return None, None\n","\n","    # 추론 실행\n","    print(\"모델 추론 실행 중...\")\n","    with torch.no_grad(): # 추론 시에는 그래디언트 계산 비활성화\n","        try:\n","            output_logits = model(input_batch) # 출력 shape: (B, NumClasses, D, H, W)\n","            print(f\"추론 완료. 출력 로짓 shape: {output_logits.shape}\")\n","        except Exception as e:\n","            print(f\"모델 추론 중 오류 발생: {e}\")\n","            traceback.print_exc()\n","            return None, None\n","\n","    # 후처리 적용\n","    try:\n","        print(\"후처리 변환 적용 중...\")\n","        # decollate_batch 대신 직접 인덱싱 사용 (배치 크기가 1이므로)\n","        # output_logits shape: (1, 1, D, H, W)\n","        # 첫 번째 배치, 첫 번째 (그리고 유일한) 채널의 텐서를 가져옴 -> shape: (1, D, H, W)\n","        # post_transforms는 이 형태(채널 차원 포함)를 처리할 수 있음\n","        logit_item = output_logits[0]  # 첫 번째 배치 아이템 선택, shape: (1, D, H, W)\n","        final_mask_tensor = post_transforms(logit_item) # 후처리 변환 바로 적용\n","        print(f\"후처리 완료. 최종 마스크 shape: {final_mask_tensor.shape}\")\n","\n","    except Exception as e:\n","        print(f\"후처리 중 오류 발생: {e}\")\n","        traceback.print_exc()\n","        return None, None\n","\n","    end_time = time.time()\n","    print(f\"추론 소요 시간: {end_time - start_time:.2f} 초.\")\n","\n","    # 최종 마스크 텐서 반환 (CPU로 이동하여 추가 처리/저장)\n","    # 메타데이터 접근 시 KeyError 방지를 위해 .get() 사용\n","\n","    meta_dict_key = f'{image_key}_meta_dict'\n","    # preprocessed_data 에서 meta_dict_key 를 찾고, 없으면 빈 딕셔너리({}) 반환\n","    original_meta_dict = preprocessed_data.get(meta_dict_key, {})\n","\n","    # original_affine = original_meta_dict.get('original_affine') # 필요하다면 여기서 affine 값만 따로 얻을 수도 있음 (없으면 None 반환)\n","    # original_spacing = original_meta_dict.get('original_spacing') # 필요하다면 여기서 spacing 값만 따로 얻을 수도 있음 (없으면 None 반환)\n","\n","    # 함수는 메타데이터 딕셔너리 전체를 반환 (있으면 내용 포함, 없으면 빈 딕셔너리)\n","    return final_mask_tensor.cpu(), original_meta_dict\n","\n","\n","# ==============================================================================\n","# 6. 시각화 함수\n","# ==============================================================================\n","def visualize_3d_mask(mask_tensor, label_pancreas, label_tumor,\n","                      step_size=2, pancreas_color='blue', tumor_color='red', opacity=0.5):\n","    \"\"\"췌장과 종양 마스크를 Plotly 3D 메쉬로 시각화합니다.\"\"\"\n","    print(\"\\n3D 시각화 생성 중...\")\n","    if mask_tensor is None:\n","        print(\"마스크 텐서가 없어 시각화할 수 없습니다.\")\n","        return\n","\n","    # 텐서를 CPU로 이동하고 numpy 배열로 변환\n","    mask_np = mask_tensor.squeeze().numpy().astype(np.uint8) # 채널 차원 제거, shape (D, H, W)\n","    print(f\"시각화용 마스크 shape: {mask_np.shape}\")\n","    print(f\"마스크 내 고유 값: {np.unique(mask_np)}\")\n","\n","    data = [] # Plotly 데이터 리스트\n","\n","    # --- 췌장 처리 ---\n","    pancreas_mask = (mask_np == label_pancreas)\n","    if np.any(pancreas_mask):\n","        print(f\"췌장(레이블 {label_pancreas}) 메쉬 생성 중...\")\n","        print(\"--- 세분화 마스크 기반: 췌장 감지됨 ---\")\n","        try:\n","            # 객체가 경계에 닿으면 marching_cubes는 패딩 필요\n","            padded_pancreas_mask = np.pad(pancreas_mask, pad_width=1, mode='constant', constant_values=0)\n","            verts, faces, _, _ = marching_cubes(padded_pancreas_mask, level=0.5, step_size=step_size)\n","            # 패딩으로 인해 이동된 정점 좌표 복원\n","            verts = verts - 1\n","            x, y, z = verts.T\n","            i, j, k = faces.T\n","\n","            mesh_pancreas = go.Mesh3d(\n","                x=z, y=y, z=x, # 좌표축은 방향(orientation)에 따라 조정 필요할 수 있음 (RAS 기준 예시)\n","                i=k, j=j, k=i,\n","                color=pancreas_color,\n","                opacity=opacity,\n","                name='Pancreas' # 범례 이름\n","            )\n","            data.append(mesh_pancreas)\n","            print(\"췌장 메쉬 생성 완료.\")\n","        except Exception as e:\n","             print(f\"췌장 메쉬 생성 실패: {e}\")\n","             traceback.print_exc()\n","    else:\n","        print(f\"췌장(레이블 {label_pancreas})에 해당하는 복셀 없음.\")\n","\n","\n","    # --- 종양 처리 ---\n","    tumor_mask = (mask_np == label_tumor)\n","    if np.any(tumor_mask):\n","        print(f\"종양(레이블 {label_tumor}) 메쉬 생성 중...\")\n","        print(\"--- 세분화 마스크 기반: 암(종양) 감지됨 ---\") # 명시적 메시지\n","        try:\n","            # Marching cubes 패딩 필요\n","            padded_tumor_mask = np.pad(tumor_mask, pad_width=1, mode='constant', constant_values=0)\n","            verts, faces, _, _ = marching_cubes(padded_tumor_mask, level=0.5, step_size=step_size)\n","            # 패딩 좌표 복원\n","            verts = verts - 1\n","            x, y, z = verts.T\n","            i, j, k = faces.T\n","\n","            mesh_tumor = go.Mesh3d(\n","                x=z, y=y, z=x, # 좌표축 조정 필요 시\n","                i=k, j=j, k=i,\n","                color=tumor_color,\n","                opacity=opacity,\n","                name='Tumor' # 범례 이름\n","            )\n","            data.append(mesh_tumor)\n","            print(\"종양 메쉬 생성 완료.\")\n","        except Exception as e:\n","            print(f\"종양 메쉬 생성 실패: {e}\")\n","            traceback.print_exc()\n","    else:\n","        print(f\"종양(레이블 {label_tumor})에 해당하는 복셀 없음.\")\n","        print(\"--- 세분화 마스크 기반: 암(종양) 감지되지 않음 ---\")\n","\n","    # --- Figure 생성 및 표시 ---\n","    if not data:\n","        print(\"생성된 메쉬가 없어 플롯을 생략합니다.\")\n","        return\n","\n","    fig = go.Figure(data=data)\n","    fig.update_layout(\n","        title='3D 세분화 시각화',\n","        scene=dict(\n","            xaxis_title='X (RAS)', # X축 레이블\n","            yaxis_title='Y (RAS)', # Y축 레이블\n","            zaxis_title='Z (RAS)', # Z축 레이블\n","            aspectratio=dict(x=1, y=1, z=mask_np.shape[0]/mask_np.shape[2]), # 영상 비율에 맞게 종횡비 조절 (Z축이 Depth일 경우)\n","            camera_eye=dict(x=1.2, y=1.2, z=1.2) # 초기 카메라 시점\n","        )\n","    )\n","    print(\"인터랙티브 3D 플롯 표시 중...\")\n","    fig.show() # 인터랙티브 플롯 창 또는 탭 열기\n","\n","\n","# ==============================================================================\n","# 7. 메인 실행 부분\n","# ==============================================================================\n","if __name__ == '__main__':\n","    print(\"--- 췌장 Multi-Class 세분화 추론 스크립트 ---\")\n","    print(f\"사용 장치: {DEVICE}\")\n","\n","    # --- 모델 로드 ---\n","    model = None\n","    try:\n","        model = load_segmentation_model(MODEL_DEFINITION, MODEL_PATH, DEVICE, num_classes=NUM_CLASSES)\n","    except Exception as e:\n","        print(f\"치명적 오류: 모델을 로드할 수 없습니다. 종료합니다.\")\n","        exit()\n","\n","    if model is None:\n","        print(\"모델 로딩 실패. 종료합니다.\")\n","        exit()\n","\n","    # --- 추론 실행 ---\n","    predicted_mask_tensor, meta_dict = None, None\n","    if not os.path.exists(INPUT_CT_PATH):\n","         print(f\"오류: 입력 CT 파일을 찾을 수 없습니다: {INPUT_CT_PATH}\")\n","    else:\n","        try:\n","            predicted_mask_tensor, meta_dict = run_inference(\n","                model, INPUT_CT_PATH, inference_transforms, post_pred_transform, DEVICE\n","            )\n","        except Exception as e:\n","            print(f\"치명적 오류: 추론 실패.\")\n","            traceback.print_exc()\n","\n","    # --- 마스크 기반 암 존재 여부 확인 ---\n","    # (visualize_3d_mask 내부에서도 확인하지만, 미리 수행 가능)\n","    cancer_detected_flag = False\n","    if predicted_mask_tensor is not None:\n","        if torch.any(predicted_mask_tensor == LABEL_TUMOR):\n","            cancer_detected_flag = True\n","            print(f\"\\n초기 확인: 모델 예측 결과에 종양 레이블({LABEL_TUMOR}) 포함됨.\")\n","        else:\n","            print(f\"\\n초기 확인: 모델 예측 결과에 종양 레이블({LABEL_TUMOR}) 포함되지 않음.\")\n","\n","        # --- 예측 마스크 저장 (선택 사항) ---\n","        # 주의: 저장은 마스크를 원본 이미지 공간으로 리샘플링해야 정확합니다.\n","        # 이는 변환(transforms)을 직접 사용하는 것보다 복잡할 수 있습니다.\n","        # 간단한 방법은 TARGET_SPATIAL_SHAPE 공간의 마스크를 저장하는 것이지만,\n","        # 리샘플링 없이는 *원본* 이미지 위에 정확히 중첩되지 않을 수 있습니다.\n","        # 편의상 처리된 마스크를 저장합니다:\n","        if OUTPUT_MASK_PATH:\n","            try:\n","                print(f\"예측 마스크 저장 중 (shape: {predicted_mask_tensor.shape}) to: {OUTPUT_MASK_PATH}\")\n","                # Affine 정보가 필요합니다. 이상적으로는 *처리된* 이미지 공간\n","                # (Orientation, Resize 등 후)에 해당하는 affine을 사용해야 합니다.\n","                # MONAI 변환은 이를 저장하지만, Resize 후의 *최종* affine에 접근하려면\n","                # 사용자 정의 처리나 InverseTransform 사용이 필요할 수 있습니다.\n","                # 대안으로 원본 affine을 사용합니다 (완벽하게 정렬되지 않을 수 있음).\n","                # 또는 TARGET_SPATIAL_SHAPE와 spacing=1 기반으로 새 affine 생성.\n","                # 원본 affine으로 저장하면 표준 NIfTI 뷰어에서 열 때\n","                # 잘못된 방향/크기로 보일 수 있습니다.\n","\n","                # numpy 배열로부터 NIfTI 이미지 객체 생성\n","                # 채널 차원이 1이면 제거\n","                mask_to_save = predicted_mask_tensor.squeeze().cpu().numpy().astype(np.uint8)\n","                # 자리 표시자로 원본 affine 사용 - 정렬 불일치 가능성 주의\n","                # 더 정확한 affine은 RAS 방향과 TARGET_SPATIAL_SHAPE를 반영해야 함\n","                affine_to_use = meta_dict.get('original_affine', np.eye(4)) if meta_dict else np.eye(4)\n","\n","                nifti_img = nib.Nifti1Image(mask_to_save.astype(np.uint8), affine=affine_to_use)\n","                nib.save(nifti_img, OUTPUT_MASK_PATH)\n","                print(\"마스크 저장 성공.\")\n","            except Exception as e:\n","                print(f\"예측 마스크 저장 오류: {e}\")\n","                traceback.print_exc()\n","\n","    # --- 시각화 ---\n","    try:\n","        visualize_3d_mask(\n","            predicted_mask_tensor,\n","            label_pancreas=LABEL_PANCREAS,\n","            label_tumor=LABEL_TUMOR,\n","            step_size=VIS_STEP_SIZE,\n","            pancreas_color=PANCREAS_COLOR,\n","            tumor_color=TUMOR_COLOR,\n","            opacity=OPACITY\n","        )\n","    except Exception as e:\n","        print(f\"시각화 중 오류 발생: {e}\")\n","        traceback.print_exc()\n","\n","    # --- 메모리 정리 ---\n","    del model, predicted_mask_tensor\n","    gc.collect()\n","    if torch.cuda.is_available():\n","        torch.cuda.empty_cache()\n","\n","    print(\"\\n--- 스크립트 종료 ---\")"]},{"cell_type":"code","source":["# -*- coding: utf-8 -*-\n","# ==============================================================================\n","# 췌장 세분화 추론 및 3D 시각화 스크립트 (HTML 저장 기능 추가)\n","# ==============================================================================\n","import os\n","import torch\n","import monai\n","from monai.transforms import (\n","    Compose, LoadImaged, EnsureChannelFirstd, Orientationd,\n","    ScaleIntensityRanged, CropForegroundd, Resized, EnsureTyped,\n","    Activations, AsDiscrete\n",")\n","from monai.data import decollate_batch\n","from monai.networks.nets import UNet # MONAI_UNet으로 학습시킨 경우\n","# 또는 학습 스크립트에서 정의한 사용자 정의 클래스 임포트:\n","# from your_training_script import Custom3DUNet\n","import nibabel as nib\n","import numpy as np\n","import plotly.graph_objects as go\n","from skimage.measure import marching_cubes # 3D 메쉬 생성용\n","import gc\n","import time\n","import traceback\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# ==============================================================================\n","# 1. 설정 (경로 및 파라미터 수정 필요)\n","# ==============================================================================\n","\n","# --- 학습된 모델 ---\n","MODEL_DEFINITION = \"Custom3DUNet\" # 또는 \"MONAI_UNet\"\n","MODEL_PATH = '/content/drive/MyDrive/2조/췌장암 영상/췌장암_로컬_수정/20250405-151938/checkpoints/best_model_20250405-151938.pth' # <<<--- 실제 경로로 수정하세요!\n","\n","# --- 분석할 새로운 CT 영상 파일 경로 ---\n","INPUT_CT_PATH = '/content/drive/MyDrive/2조/췌장암 영상/췌장암_로컬_수정/pancreas_025.nii' # <<<--- 실제 경로로 수정하세요!\n","\n","# --- 출력 ---\n","OUTPUT_MASK_PATH = None # 예측 마스크 저장 경로 (저장 안 함: None)\n","# <<<--- [추가된 부분] 3D 시각화 HTML 파일 저장 경로 ---\n","HTML_OUTPUT_PATH = 'pancreas_3d_visualization.html' # 원하는 파일명으로 변경 가능\n","\n","# --- 모델 및 전처리 파라미터 (학습 시와 동일해야 함) ---\n","TARGET_SPATIAL_SHAPE = (64, 96, 96)\n","HU_WINDOW = (-100, 240)\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","NUM_CLASSES = 3\n","\n","# --- 모델 아키텍처 파라미터 (Custom3DUNet 사용 시) ---\n","CUSTOM_UNET_FILTERS = [16, 32, 64, 128]\n","CUSTOM_UNET_DROPOUT = 0.15\n","CUSTOM_UNET_ACTIVATION = 'leaky_relu'\n","CUSTOM_UNET_LEAKY_SLOPE = 0.01\n","\n","# --- 모델 아키텍처 파라미터 (MONAI_UNet 사용 시) ---\n","MONAI_UNET_SPATIAL_DIMS = 3\n","MONAI_UNET_CHANNELS = (16, 32, 64, 128, 256)\n","MONAI_UNET_STRIDES = (2, 2, 2, 2)\n","MONAI_UNET_NUM_RES_UNITS = 2\n","MONAI_UNET_DROPOUT = 0.15\n","\n","# --- 시각화 파라미터 ---\n","VIS_STEP_SIZE = 2\n","PANCREAS_COLOR = 'rgb(107, 174, 214)'\n","TUMOR_COLOR = 'rgb(255, 0, 0)'\n","OPACITY = 0.5\n","\n","# --- 레이블 정의 ---\n","LABEL_PANCREAS = 1\n","LABEL_TUMOR = 2\n","\n","\n","# ==============================================================================\n","# 2. 필요한 클래스/함수 재정의 또는 임포트\n","# ==============================================================================\n","def get_activation(activation_type, negative_slope=0.01):\n","    if activation_type.lower() == 'relu': return nn.ReLU(inplace=True)\n","    elif activation_type.lower() == 'leaky_relu': return nn.LeakyReLU(negative_slope=negative_slope, inplace=True)\n","    else: raise ValueError(f\"지원하지 않는 활성화 함수 타입: {activation_type}\")\n","\n","class Custom3DUNet(nn.Module):\n","    # (사용자 정의 UNet 클래스 정의는 원본과 동일하게 유지)\n","    def __init__(self, in_channels=1, out_channels=3, filters=[16, 32, 64, 128], dropout_rate=0.1, activation='relu', leaky_slope=0.01):\n","        super().__init__()\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.filters = filters\n","        self.dropout_rate = dropout_rate\n","        self.activation = activation\n","        self.leaky_slope = leaky_slope\n","\n","        self.encoders = nn.ModuleList()\n","        self.pools = nn.ModuleList()\n","        self.decoders = nn.ModuleList()\n","        self.upconvs = nn.ModuleList()\n","\n","        def conv_block(ic, oc, act, ls, dr):\n","            layers = [\n","                nn.Conv3d(ic, oc, kernel_size=3, padding=1, bias=False), nn.BatchNorm3d(oc), get_activation(act, ls),\n","                nn.Conv3d(oc, oc, kernel_size=3, padding=1, bias=False), nn.BatchNorm3d(oc), get_activation(act, ls),\n","            ]\n","            if dr > 0.0: layers.append(nn.Dropout3d(dr))\n","            return nn.Sequential(*layers)\n","\n","        current_channels = in_channels\n","        for i, f in enumerate(filters):\n","            current_dropout = dropout_rate * (i / (len(filters) - 1)) if len(filters) > 1 and dropout_rate > 0 else 0.0\n","            encoder = conv_block(current_channels, f, self.activation, self.leaky_slope, current_dropout)\n","            pool = nn.MaxPool3d(kernel_size=2, stride=2)\n","            self.encoders.append(encoder)\n","            self.pools.append(pool)\n","            current_channels = f\n","\n","        bn_filters = filters[-1] * 2\n","        self.bottleneck = conv_block(current_channels, bn_filters, self.activation, self.leaky_slope, dropout_rate)\n","\n","        current_channels = bn_filters\n","        reversed_filters = list(reversed(filters))\n","        for i, f in enumerate(reversed_filters):\n","            upconv = nn.ConvTranspose3d(current_channels, f, kernel_size=2, stride=2)\n","            self.upconvs.append(upconv)\n","            concat_channels = f + f\n","            current_dropout = dropout_rate * ((len(filters) - 1 - i) / (len(filters) - 1)) if len(filters) > 1 and dropout_rate > 0 else 0.0\n","            decoder = conv_block(concat_channels, f, self.activation, self.leaky_slope, current_dropout)\n","            self.decoders.append(decoder)\n","            current_channels = f\n","\n","        self.output_conv = nn.Conv3d(current_channels, out_channels, kernel_size=1)\n","\n","    def forward(self, x):\n","        skips = []\n","        for i in range(len(self.filters)):\n","            x = self.encoders[i](x); skips.append(x); x = self.pools[i](x)\n","        x = self.bottleneck(x)\n","        skips = list(reversed(skips))\n","        for i in range(len(self.filters)):\n","            x = self.upconvs[i](x)\n","            skip_connection = skips[i]\n","            if x.shape[2:] != skip_connection.shape[2:]:\n","                target_shape = x.shape[2:]\n","                skip_shape = skip_connection.shape[2:]\n","                try:\n","                    crop_slices = [slice((skip_shape[d] - target_shape[d]) // 2, (skip_shape[d] + target_shape[d]) // 2) for d in range(3)]\n","                    skip_connection = skip_connection[(slice(None), slice(None)) + tuple(crop_slices)]\n","                    if x.shape != skip_connection.shape:\n","                        padding = []\n","                        for d_idx in range(3):\n","                            pad_total = x.shape[d_idx+2] - skip_connection.shape[d_idx+2]\n","                            pad_before = pad_total // 2\n","                            pad_after = pad_total - pad_before\n","                            padding.extend([pad_before, pad_after])\n","                        padding = padding[::-1]\n","                        if all(p >= 0 for p in padding):\n","                            skip_connection = F.pad(skip_connection, padding)\n","                            print(f\"  Skip connection을 다음 크기로 패딩: {skip_connection.shape}\")\n","                        else:\n","                            print(f\"오류: 크기 불일치 해결 불가. Upconv: {x.shape}, Skip (크롭 시도 후): {skip_connection.shape}\")\n","                except Exception as crop_e:\n","                    print(f\"  Skip connection 처리 중 오류: {crop_e}\")\n","            x = torch.cat((skip_connection, x), dim=1)\n","            x = self.decoders[i](x)\n","        x = self.output_conv(x)\n","        return x\n","\n","# ==============================================================================\n","# 3. 추론용 전처리 및 후처리 정의\n","# ==============================================================================\n","image_key = \"image\"\n","inference_transforms = Compose(\n","    [\n","        LoadImaged(keys=[image_key]),\n","        EnsureChannelFirstd(keys=[image_key]),\n","        Orientationd(keys=[image_key], axcodes=\"RAS\"),\n","        ScaleIntensityRanged(keys=[image_key], a_min=HU_WINDOW[0], a_max=HU_WINDOW[1], b_min=0.0, b_max=1.0, clip=True),\n","        CropForegroundd(keys=[image_key], source_key=image_key, allow_smaller=True),\n","        Resized(keys=[image_key], spatial_size=TARGET_SPATIAL_SHAPE, mode=\"area\"),\n","        EnsureTyped(keys=[image_key], dtype=torch.float32),\n","    ]\n",")\n","post_pred_transform = Compose([Activations(softmax=True), AsDiscrete(argmax=True)])\n","\n","# ==============================================================================\n","# 4. 모델 로드 함수 (원본과 동일)\n","# ==============================================================================\n","def load_segmentation_model(model_def_name, model_path, device, num_classes=3):\n","    print(f\"모델 로딩 중 '{model_def_name}' from: {model_path}\")\n","    if not os.path.exists(model_path):\n","        raise FileNotFoundError(f\"모델 체크포인트 파일을 찾을 수 없습니다: {model_path}\")\n","    if model_def_name == \"Custom3DUNet\":\n","        model = Custom3DUNet(\n","            in_channels=1, out_channels=num_classes,\n","            filters=CUSTOM_UNET_FILTERS, dropout_rate=CUSTOM_UNET_DROPOUT,\n","            activation=CUSTOM_UNET_ACTIVATION, leaky_slope=CUSTOM_UNET_LEAKY_SLOPE\n","        )\n","        print(f\"Custom3DUNet 로드 완료 (out_channels={num_classes})\")\n","    elif model_def_name == \"MONAI_UNet\":\n","        model = UNet(\n","            spatial_dims=MONAI_UNET_SPATIAL_DIMS, in_channels=1, out_channels=num_classes,\n","            channels=MONAI_UNET_CHANNELS, strides=MONAI_UNET_STRIDES,\n","            num_res_units=MONAI_UNET_NUM_RES_UNITS, act='PRELU', norm='BATCH',\n","            dropout=MONAI_UNET_DROPOUT\n","        )\n","        print(f\"MONAI_UNet 로드 완료 (out_channels={num_classes})\")\n","    else:\n","        raise ValueError(f\"알 수 없는 모델 정의 이름: {model_def_name}\")\n","    try:\n","        checkpoint = torch.load(model_path, map_location=device)\n","        if 'model_state_dict' in checkpoint:\n","            model.load_state_dict(checkpoint['model_state_dict'])\n","            print(f\"모델 상태 로드 완료 (epoch {checkpoint.get('epoch', 'N/A')})\")\n","        elif 'state_dict' in checkpoint:\n","            model.load_state_dict(checkpoint['state_dict'])\n","            print(\"모델 상태 로드 완료 (key 'state_dict')\")\n","        else:\n","            model.load_state_dict(checkpoint)\n","            print(\"모델 상태 로드 완료 (직접 로드)\")\n","        model.to(device)\n","        model.eval()\n","        print(\"모델 로드 및 평가 모드 설정 완료.\")\n","        return model\n","    except Exception as e:\n","        print(f\"모델 체크포인트 로드 오류: {e}\")\n","        traceback.print_exc()\n","        raise\n","\n","# ==============================================================================\n","# 5. 추론 함수 (원본과 동일)\n","# ==============================================================================\n","def run_inference(model, input_image_path, pre_transforms, post_transforms, device, out_key=\"pred\"):\n","    print(f\"\\n추론 시작: {input_image_path}\")\n","    start_time = time.time()\n","    input_data = {image_key: input_image_path}\n","    try:\n","        print(\"전처리 변환 적용 중...\")\n","        preprocessed_data = pre_transforms(input_data)\n","        input_tensor = preprocessed_data[image_key]\n","        print(f\"전처리 완료. 입력 텐서 shape: {input_tensor.shape}\")\n","        input_batch = input_tensor.unsqueeze(0).to(device)\n","    except Exception as e:\n","        print(f\"전처리 중 오류 발생: {e}\")\n","        traceback.print_exc()\n","        return None, None\n","    print(\"모델 추론 실행 중...\")\n","    with torch.no_grad():\n","        try:\n","            output_logits = model(input_batch)\n","            print(f\"추론 완료. 출력 로짓 shape: {output_logits.shape}\")\n","        except Exception as e:\n","            print(f\"모델 추론 중 오류 발생: {e}\")\n","            traceback.print_exc()\n","            return None, None\n","    try:\n","        print(\"후처리 변환 적용 중...\")\n","        logit_item = output_logits[0]\n","        final_mask_tensor = post_transforms(logit_item)\n","        print(f\"후처리 완료. 최종 마스크 shape: {final_mask_tensor.shape}\")\n","    except Exception as e:\n","        print(f\"후처리 중 오류 발생: {e}\")\n","        traceback.print_exc()\n","        return None, None\n","    end_time = time.time()\n","    print(f\"추론 소요 시간: {end_time - start_time:.2f} 초.\")\n","    meta_dict_key = f'{image_key}_meta_dict'\n","    original_meta_dict = preprocessed_data.get(meta_dict_key, {})\n","    return final_mask_tensor.cpu(), original_meta_dict\n","\n","# ==============================================================================\n","# 6. 시각화 함수 (HTML 저장 기능 추가)\n","# ==============================================================================\n","def visualize_3d_mask(mask_tensor, label_pancreas, label_tumor,\n","                      step_size=2, pancreas_color='blue', tumor_color='red', opacity=0.5,\n","                      html_output_path=None): # <<<--- [수정된 부분] html_output_path 인자 추가\n","    \"\"\"췌장과 종양 마스크를 Plotly 3D 메쉬로 시각화하고 HTML로 저장합니다.\"\"\"\n","    print(\"\\n3D 시각화 생성 중...\")\n","    if mask_tensor is None:\n","        print(\"마스크 텐서가 없어 시각화할 수 없습니다.\")\n","        return\n","\n","    mask_np = mask_tensor.squeeze().numpy().astype(np.uint8)\n","    print(f\"시각화용 마스크 shape: {mask_np.shape}\")\n","    print(f\"마스크 내 고유 값: {np.unique(mask_np)}\")\n","    data = []\n","\n","    # --- 췌장 처리 ---\n","    pancreas_mask = (mask_np == label_pancreas)\n","    if np.any(pancreas_mask):\n","        print(f\"췌장(레이블 {label_pancreas}) 메쉬 생성 중...\")\n","        print(\"--- 세분화 마스크 기반: 췌장 감지됨 ---\")\n","        try:\n","            padded_pancreas_mask = np.pad(pancreas_mask, pad_width=1, mode='constant', constant_values=0)\n","            verts, faces, _, _ = marching_cubes(padded_pancreas_mask, level=0.5, step_size=step_size)\n","            verts = verts - 1\n","            x, y, z = verts.T\n","            i, j, k = faces.T\n","            mesh_pancreas = go.Mesh3d(\n","                x=z, y=y, z=x, i=k, j=j, k=i,\n","                color=pancreas_color, opacity=opacity, name='Pancreas'\n","            )\n","            data.append(mesh_pancreas)\n","            print(\"췌장 메쉬 생성 완료.\")\n","        except Exception as e:\n","            print(f\"췌장 메쉬 생성 실패: {e}\")\n","            traceback.print_exc()\n","    else:\n","        print(f\"췌장(레이블 {label_pancreas})에 해당하는 복셀 없음.\")\n","\n","    # --- 종양 처리 ---\n","    tumor_mask = (mask_np == label_tumor)\n","    if np.any(tumor_mask):\n","        print(f\"종양(레이블 {label_tumor}) 메쉬 생성 중...\")\n","        print(\"--- 세분화 마스크 기반: 암(종양) 감지됨 ---\")\n","        try:\n","            padded_tumor_mask = np.pad(tumor_mask, pad_width=1, mode='constant', constant_values=0)\n","            verts, faces, _, _ = marching_cubes(padded_tumor_mask, level=0.5, step_size=step_size)\n","            verts = verts - 1\n","            x, y, z = verts.T\n","            i, j, k = faces.T\n","            mesh_tumor = go.Mesh3d(\n","                x=z, y=y, z=x, i=k, j=j, k=i,\n","                color=tumor_color, opacity=opacity, name='Tumor'\n","            )\n","            data.append(mesh_tumor)\n","            print(\"종양 메쉬 생성 완료.\")\n","        except Exception as e:\n","            print(f\"종양 메쉬 생성 실패: {e}\")\n","            traceback.print_exc()\n","    else:\n","        print(f\"종양(레이블 {label_tumor})에 해당하는 복셀 없음.\")\n","        print(\"--- 세분화 마스크 기반: 암(종양) 감지되지 않음 ---\")\n","\n","    if not data:\n","        print(\"생성된 메쉬가 없어 플롯을 생략합니다.\")\n","        return\n","\n","    fig = go.Figure(data=data)\n","    fig.update_layout(\n","        title='3D 세분화 시각화',\n","        scene=dict(\n","            xaxis_title='X (RAS)', yaxis_title='Y (RAS)', zaxis_title='Z (RAS)',\n","            aspectratio=dict(x=1, y=1, z=mask_np.shape[0]/mask_np.shape[2]),\n","            camera_eye=dict(x=1.2, y=1.2, z=1.2)\n","        )\n","    )\n","\n","    # <<<--- [추가된 부분] HTML 파일 저장 ---\n","    if html_output_path:\n","        try:\n","            print(f\"3D 시각화 결과를 HTML 파일로 저장 중: {html_output_path}\")\n","            fig.write_html(html_output_path)\n","            print(\"HTML 파일 저장 성공.\")\n","        except Exception as e:\n","            print(f\"HTML 파일 저장 중 오류 발생: {e}\")\n","            traceback.print_exc()\n","\n","    print(\"인터랙티브 3D 플롯 표시 중...\")\n","    fig.show()\n","\n","# ==============================================================================\n","# 7. 메인 실행 부분\n","# ==============================================================================\n","if __name__ == '__main__':\n","    print(\"--- 췌장 Multi-Class 세분화 추론 스크립트 ---\")\n","    print(f\"사용 장치: {DEVICE}\")\n","\n","    model = None\n","    try:\n","        model = load_segmentation_model(MODEL_DEFINITION, MODEL_PATH, DEVICE, num_classes=NUM_CLASSES)\n","    except Exception as e:\n","        print(f\"치명적 오류: 모델을 로드할 수 없습니다. 종료합니다.\")\n","        exit()\n","\n","    if model is None:\n","        print(\"모델 로딩 실패. 종료합니다.\")\n","        exit()\n","\n","    predicted_mask_tensor, meta_dict = None, None\n","    if not os.path.exists(INPUT_CT_PATH):\n","        print(f\"오류: 입력 CT 파일을 찾을 수 없습니다: {INPUT_CT_PATH}\")\n","    else:\n","        try:\n","            predicted_mask_tensor, meta_dict = run_inference(\n","                model, INPUT_CT_PATH, inference_transforms, post_pred_transform, DEVICE\n","            )\n","        except Exception as e:\n","            print(f\"치명적 오류: 추론 실패.\")\n","            traceback.print_exc()\n","\n","    if predicted_mask_tensor is not None:\n","        if torch.any(predicted_mask_tensor == LABEL_TUMOR):\n","            print(f\"\\n초기 확인: 모델 예측 결과에 종양 레이블({LABEL_TUMOR}) 포함됨.\")\n","        else:\n","            print(f\"\\n초기 확인: 모델 예측 결과에 종양 레이블({LABEL_TUMOR}) 포함되지 않음.\")\n","\n","        if OUTPUT_MASK_PATH:\n","            try:\n","                print(f\"예측 마스크 저장 중 to: {OUTPUT_MASK_PATH}\")\n","                mask_to_save = predicted_mask_tensor.squeeze().cpu().numpy().astype(np.uint8)\n","                affine_to_use = meta_dict.get('original_affine', np.eye(4)) if meta_dict else np.eye(4)\n","                nifti_img = nib.Nifti1Image(mask_to_save.astype(np.uint8), affine=affine_to_use)\n","                nib.save(nifti_img, OUTPUT_MASK_PATH)\n","                print(\"마스크 저장 성공.\")\n","            except Exception as e:\n","                print(f\"예측 마스크 저장 오류: {e}\")\n","                traceback.print_exc()\n","\n","    # --- 시각화 ---\n","    try:\n","        visualize_3d_mask(\n","            predicted_mask_tensor,\n","            label_pancreas=LABEL_PANCREAS,\n","            label_tumor=LABEL_TUMOR,\n","            step_size=VIS_STEP_SIZE,\n","            pancreas_color=PANCREAS_COLOR,\n","            tumor_color=TUMOR_COLOR,\n","            opacity=OPACITY,\n","            html_output_path=HTML_OUTPUT_PATH # <<<--- [수정된 부분] HTML 경로 전달\n","        )\n","    except Exception as e:\n","        print(f\"시각화 중 오류 발생: {e}\")\n","        traceback.print_exc()\n","\n","    # --- 메모리 정리 ---\n","    del model, predicted_mask_tensor\n","    gc.collect()\n","    if torch.cuda.is_available():\n","        torch.cuda.empty_cache()\n","\n","    print(\"\\n--- 스크립트 종료 ---\")"],"metadata":{"id":"Fym-L4Lezv7O","executionInfo":{"status":"ok","timestamp":1750984499385,"user_tz":-540,"elapsed":6545,"user":{"displayName":"구글개정","userId":"15305168374719957285"}},"outputId":"a75564d2-1153-4d9f-b4e8-4174d42ee162","colab":{"base_uri":"https://localhost:8080/","height":1000}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["--- 췌장 Multi-Class 세분화 추론 스크립트 ---\n","사용 장치: cpu\n","모델 로딩 중 'Custom3DUNet' from: /content/drive/MyDrive/2조/췌장암 영상/췌장암_로컬_수정/20250405-151938/checkpoints/best_model_20250405-151938.pth\n","Custom3DUNet 로드 완료 (out_channels=3)\n","모델 상태 로드 완료 (epoch 96)\n","모델 로드 및 평가 모드 설정 완료.\n","\n","추론 시작: /content/drive/MyDrive/2조/췌장암 영상/췌장암_로컬_수정/pancreas_025.nii\n","전처리 변환 적용 중...\n","전처리 완료. 입력 텐서 shape: torch.Size([1, 64, 96, 96])\n","모델 추론 실행 중...\n","추론 완료. 출력 로짓 shape: torch.Size([1, 3, 64, 96, 96])\n","후처리 변환 적용 중...\n","후처리 완료. 최종 마스크 shape: torch.Size([1, 64, 96, 96])\n","추론 소요 시간: 4.14 초.\n","\n","초기 확인: 모델 예측 결과에 종양 레이블(2) 포함됨.\n","\n","3D 시각화 생성 중...\n","시각화용 마스크 shape: (64, 96, 96)\n","마스크 내 고유 값: [0 1 2]\n","췌장(레이블 1) 메쉬 생성 중...\n","--- 세분화 마스크 기반: 췌장 감지됨 ---\n","췌장 메쉬 생성 완료.\n","종양(레이블 2) 메쉬 생성 중...\n","--- 세분화 마스크 기반: 암(종양) 감지됨 ---\n","종양 메쉬 생성 완료.\n","3D 시각화 결과를 HTML 파일로 저장 중: pancreas_3d_visualization.html\n","HTML 파일 저장 성공.\n","인터랙티브 3D 플롯 표시 중...\n"]},{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"67e6d1ac-8909-46c1-b3b6-1b92fc5633a4\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"67e6d1ac-8909-46c1-b3b6-1b92fc5633a4\")) {                    Plotly.newPlot(                        \"67e6d1ac-8909-46c1-b3b6-1b92fc5633a4\",                        [{\"color\":\"rgb(107, 174, 214)\",\"i\":[0,2,4,5,6,6,7,6,4,7,10,8,2,1,3,3,2,13,16,16,18,20,20,5,3,8,6,6,6,22,21,23,26,27,20,28,5,5,20,9,29,10,10,30,24,32,33,32,26,34,34,26,29,37,30,38,39,39,38,32,41,33,35,37,43,38,44,39,12,46,46,47,47,48,18,17,19,18,45,45,52,46,15,21,23,21,54,55,56,56,56,27,25,55,60,61,27,27,56,34,40,64,64,65,59,65,60,66,66,60,36,36,62,42,69,71,71,72,63,63,73,64,67,69,75,70,76,71,47,47,50,79,79,80,52,51,77,77,82,48,48,53,84,84,54,54,58,57,78,78,88,79,84,89,89,90,57,86,65,65,65,59,94,94,95,66,72,97,97,98,92,92,99,93,94,101,74,74,74,74,101,75,103,76,71,71,71,97,101,103,108,104,109,105,80,80,110,81,111,82,112,83,87,87,114,88,79,79,79,111,118,112,119,113,120,85,85,89,121,122,114,114,86,115,125,116,126,126,126,93,91,123,98,126,126,126,130,93,132,132,133,100,106,106,106,134,136,135,137,138,102,102,132,107,139,108,140,109,109,141,143,143,142,136,137,145,145,137,140,148,141,149,150,150,149,143,146,148,153,149,154,150,117,117,155,118,156,119,157,120,158,121,124,124,160,125,116,116,116,156,164,157,165,158,166,127,127,127,158,122,160,123,169,169,168,162,128,167,168,168,129,169,131,171,133,172,144,177,177,177,176,177,180,180,181,145,151,151,151,182,184,184,183,179,186,187,147,147,180,152,188,153,189,154,154,190,192,192,191,184,194,195,188,196,197,197,196,190,199,191,200,192,194,196,202,197,163,163,203,164,204,165,205,166,170,170,170,207,204,209,205,210,206,211,167,206,173,173,173,212,208,214,215,215,214,210,217,211,218,218,218,219,212,172,221,221,220,214,223,215,174,177,224,225,220,220,175,221,185,229,229,229,228,229,232,232,232,187,193,193,193,235,230,237,238,237,239,240,187,232,198,198,241,199,242,200,200,243,236,245,237,246,247,246,248,240,240,239,195,195,239,201,252,202,202,253,242,255,243,256,244,257,245,258,259,259,258,247,248,251,262,252,263,253,264,254,265,255,266,256,267,257,268,258,269,259,216,216,270,217,271,218,222,222,273,223,223,274,271,276,272,277,219,219,272,224,227,227,227,279,274,281,275,282,276,283,277,284,278,285,225,225,278,229,234,234,234,287,280,289,290,290,289,282,292,292,292,282,295,295,294,296,296,284,286,299,231,286,287,233,301,301,300,289,303,290,294,295,298,305,305,298,238,299,250,249,300,300,310,301,311,306,313,313,313,247,314,314,315,261,314,262,316,263,317,264,318,265,319,266,320,267,321,268,322,269,259,259,259,313,314,326,326,314,317,329,318,330,319,331,320,332,321,333,322,334,335,335,334,324,327,337,337,327,340,340,338,331,342,332,343,333,344,334,345,335,338,340,291,291,347,292,296,296,350,350,352,354,353,355,302,302,358,303,303,359,348,361,293,293,348,304,304,362,297,297,349,305,350,354,366,356,367,357,309,309,368,310,310,369,359,371,360,372,373,373,372,362,375,363,376,376,376,363,306,306,364,312,368,308,381,381,380,370,383,371,384,372,385,373,386,387,325,325,379,313,388,388,380,380,390,328,336,336,335,324,392,392,394,388,388,389,328,328,389,337,341,341,399,342,400,402,402,403,345,344,391,404,392,396,406,397,407,398,408,339,339,346,399,399,410,400,411,401,412,402,413,415,417,417,419,421,420,423,422,425,424,427,426,429,428,414,414,413,433,433,434,433,436,418,418,417,352,352,421,353,423,353,353,441,423,442,440,423,440,441,441,357,425,445,429,446,431,447,432,448,434,449,450,450,451,450,436,453,453,436,351,351,439,365,456,367,458,442,366,459,457,458,367,458,441,367,445,460,462,462,461,463,463,446,448,466,449,467,468,468,467,452,374,374,470,375,471,376,454,456,474,474,474,456,460,477,461,478,479,479,480,480,480,480,464,466,483,483,483,466,486,484,382,488,488,489,384,383,385,384,470,470,492,492,492,470,472,495,377,472,475,477,497,497,497,477,480,500,501,500,484,486,390,390,381,381,381,488,506,493,493,494,495,510,387,495,498,511,511,498,514,512,394,394,515,395,395,516,518,517,519,508,508,506,403,403,509,404,510,391,512,512,512,512,525,525,526,529,393,527,405,528,531,515,530,406,533,516,532,407,533,535,407,536,409,408,410,409,521,521,538,412,522,402,525,528,540,530,541,532,542,534,543,535,544,544,546,548,547,549,415,415,553,553,553,555,545,545,556,422,548,424,550,550,550,424,428,426,430,428,552,552,560,416,416,433,561,562,438,438,437,418,564,564,565,567,567,568,444,444,443,570,571,573,575,575,576,450,577,577,578,453,579,580,567,581,442,442,567,459,459,582,463,463,572,465,463,463,463,584,585,587,469,469,468,452,577,455,455,473,579,591,593,473,474,595,592,581,582,597,583,598,462,462,583,599,599,599,584,483,586,485,483,483,483,602,603,486,589,604,603,605,489,489,608,490,609,491,610,492,593,593,496,595,595,615,614,612,596,596,616,595,613,497,618,618,617,598,499,619,598,619,617,618,618,598,482,599,485,602,502,622,486,623,606,624,504,504,504,607,608,608,626,626,626,608,610,629,507,507,611,493,613,617,631,499,499,511,511,511,620,513,621,633,513,633,620,634,634,636,637,622,622,623,624,641,504,624,642,627,627,628,520,520,629,508,513,523,636,526,646,647,523,526,647,527,637,648,638,650,649,651,640,529,652,653,641,531,641,536,653,655,644,644,655,538,645,521,524,540,648,541,650,542,651,543,653,535,656,658,658,658,546,546,660,547,661,549,555,554,657,657,664,659,556,661,666,662,667,551,551,557,669,669,558,558,669,559,671,560,672,561,554,663,565,676,676,677,569,568,679,679,571,573,681,670,571,682,679,681,573,681,573,684,682,671,672,686,673,687,562,673,688,688,674,688,675,566,692,691,679,683,694,683,585,684,684,697,696,694,685,685,587,695,686,698,684,588,588,699,576,687,578,689,689,590,591,701,691,700,592,702,701,591,701,596,592,592,592,703,706,697,697,695,710,710,711,712,588,710,601,711,713,714,699,601,699,602,589,715,713,603,715,605,594,612,612,718,704,717,614,719,718,612,718,704,704,614,618,616,620,620,620,721,709,723,711,724,713,725,622,622,715,725,727,726,725,726,715,727,727,715,607,607,716,625,730,626,615,630,631,630,632,631,634,635,736,632,735,636,722,738,739,739,738,740,741,724,638,725,742,743,622,744,639,745,743,742,743,728,728,729,730,747,643,643,731,627,635,646,646,646,748,739,638,652,745,654,746,655,747,644,658,658,664,664,664,750,659,659,749,665,752,666,753,667,754,668,750,663,751,757,752,758,677,677,753,678,760,677,761,753,762,762,759,755,680,763,755,763,759,764,682,682,682,682,674,690,690,766,767,767,766,758,758,758,770,760,760,759,680,680,759,694,773,765,693,774,772,773,694,773,775,776,764,694,764,697,685,777,775,696,690,702,700,700,700,770,780,705,705,781,772,782,783,708,782,775,697,783,776,786,698,698,777,710,787,712,702,719,717,717,717,790,790,781,789,705,791,789,791,781,792,794,782,720,707,794,785,796,786,797,787,798,788,799,714,714,788,727,719,733,793,734,794,736,796,737,737,801,740,740,798,742,799,744,800,728,737,739,761,761,802,762,768,768,804,769,769,805,803,807,765,765,803,774,767,780,780,809,806,810,807,811,784,784,808,776,780,792,810,795,811,785],\"j\":[1,3,1,1,0,7,4,8,9,9,9,10,11,11,13,2,12,15,17,19,19,19,11,11,14,21,21,15,14,23,23,25,17,17,28,26,9,29,29,10,9,8,22,22,32,31,24,24,34,35,26,28,37,35,38,37,31,38,30,40,40,41,42,42,42,43,43,44,11,12,47,13,15,15,49,49,18,50,11,19,19,45,48,15,21,53,25,25,57,58,49,49,55,59,57,57,34,62,62,36,63,63,40,40,41,41,66,67,60,62,42,69,69,43,42,70,43,43,44,73,72,73,74,74,74,75,75,76,46,77,49,50,80,51,51,80,46,52,52,77,82,82,83,54,53,84,86,86,49,58,58,78,85,55,90,59,61,61,92,93,59,90,61,95,91,68,96,96,72,72,73,99,98,99,100,102,101,100,94,75,74,76,75,105,105,106,96,106,107,107,107,108,108,109,79,111,111,112,112,113,113,113,86,115,115,115,88,116,117,110,111,111,112,112,113,113,120,120,90,90,123,86,91,114,115,115,127,122,93,90,95,95,130,128,131,98,98,126,95,133,129,102,134,97,130,130,130,130,133,133,107,139,139,108,107,109,108,105,134,134,135,142,134,144,145,146,137,139,148,146,149,148,142,149,141,151,152,152,152,153,153,154,116,156,156,157,157,158,158,159,159,159,123,161,161,161,125,162,163,155,156,156,157,157,158,167,158,159,166,159,129,129,170,161,161,161,167,171,172,129,133,168,171,174,138,138,176,136,176,178,144,179,138,181,175,147,182,143,176,176,178,183,176,185,181,181,152,188,188,153,152,154,153,150,182,182,183,191,182,193,187,187,196,194,189,196,188,198,198,199,199,200,201,201,201,202,162,204,204,205,205,206,206,206,169,203,207,208,203,203,204,204,205,205,211,211,172,207,212,213,207,207,216,209,209,209,210,210,211,171,219,174,175,175,222,213,213,213,214,214,219,174,179,179,226,175,181,220,228,179,228,230,185,231,233,234,226,226,235,184,228,228,237,236,230,230,233,233,195,187,241,199,198,200,199,192,235,235,245,244,246,245,237,237,249,248,239,251,201,252,252,202,201,197,241,241,255,254,256,255,257,256,258,257,246,258,245,260,261,261,261,262,262,263,263,264,264,265,265,266,266,267,267,268,268,269,215,271,271,272,272,272,221,274,274,270,274,275,270,270,271,271,278,272,277,278,226,273,279,280,273,273,274,274,275,275,276,276,277,277,286,278,285,286,233,279,287,288,279,279,291,281,281,281,282,293,294,294,296,284,284,297,298,298,285,285,299,299,240,240,302,288,288,288,289,289,293,294,297,306,307,307,307,307,308,308,240,250,250,300,259,312,307,247,311,313,249,315,308,262,261,263,262,264,263,265,264,266,265,267,266,268,267,269,268,324,324,325,311,325,326,327,314,316,329,327,330,329,331,330,332,331,333,332,334,333,323,334,322,336,337,338,327,329,330,338,329,341,341,342,342,343,343,344,344,345,346,346,290,348,348,348,295,349,351,353,353,355,355,357,301,359,359,347,359,360,347,347,362,348,361,349,362,363,364,349,363,364,365,365,365,366,366,367,308,369,369,358,369,370,358,358,359,359,374,361,361,361,362,362,363,377,378,378,379,364,378,379,315,315,382,369,369,369,370,370,371,371,372,372,378,386,386,379,378,379,326,315,315,388,381,389,386,387,387,386,393,395,395,396,389,397,337,398,398,339,399,342,341,343,342,401,343,343,404,404,345,345,405,405,405,406,406,407,407,408,346,409,346,410,409,410,410,411,411,412,414,416,418,420,420,422,422,424,424,426,426,428,428,430,430,431,413,432,413,434,432,435,437,436,417,439,351,439,439,352,353,440,441,353,442,423,443,425,425,443,444,355,445,425,446,445,447,446,448,447,449,448,434,451,449,452,453,454,436,439,365,456,456,366,365,458,441,366,442,457,459,460,460,459,459,357,460,445,446,461,445,464,446,447,466,464,467,466,451,467,449,469,373,471,471,472,472,472,473,473,473,475,456,457,477,475,478,477,461,480,478,481,464,479,480,481,481,484,466,467,467,467,381,382,489,383,383,489,384,490,373,385,385,493,494,494,471,471,495,495,496,496,496,498,477,478,500,498,480,480,502,502,388,503,390,504,505,487,507,507,506,506,494,494,510,510,511,512,498,500,500,500,393,516,516,503,516,517,504,518,520,520,519,519,522,509,506,509,509,510,523,524,525,514,512,527,527,515,527,393,528,405,516,529,406,530,517,531,407,532,518,534,536,407,537,537,538,538,411,538,410,519,519,522,539,539,539,540,540,541,541,542,542,543,545,547,547,549,549,551,414,552,554,419,555,556,544,420,420,420,422,422,424,551,557,557,426,557,428,558,414,430,430,552,560,560,435,435,554,437,563,438,565,567,564,442,443,443,570,571,571,572,570,572,450,435,435,575,437,578,563,455,564,579,564,564,582,567,581,570,582,583,583,572,570,584,465,585,574,586,584,586,575,576,576,575,590,590,473,591,580,593,591,474,476,592,595,579,581,581,582,582,599,583,598,465,584,482,599,584,584,600,485,601,588,601,604,589,486,605,605,607,488,609,609,610,610,611,611,611,612,476,595,496,613,614,615,596,612,593,597,614,497,613,619,617,618,499,598,497,597,597,497,620,621,621,621,621,502,600,622,502,623,486,624,623,625,606,624,625,488,505,505,627,628,628,609,609,629,611,610,611,630,630,630,631,511,632,633,620,511,621,513,634,635,635,634,501,636,514,638,637,623,640,641,640,518,504,643,643,642,642,645,629,628,629,646,646,526,636,647,646,524,648,648,637,527,638,648,649,651,649,531,637,653,652,533,640,518,653,536,654,537,655,536,642,642,645,539,647,647,648,648,650,650,651,651,653,657,545,546,659,658,661,661,662,662,662,663,663,656,556,556,665,656,660,661,661,662,662,667,667,668,558,557,671,671,672,672,673,673,673,563,563,675,675,565,565,678,678,680,678,678,681,669,571,670,679,682,683,683,682,574,682,684,669,671,671,672,672,687,687,578,674,563,689,691,675,675,675,693,693,693,574,684,585,695,696,697,685,694,683,695,587,698,686,696,686,699,687,699,699,590,700,590,591,701,580,700,691,702,592,594,594,592,703,703,692,691,705,707,706,695,709,695,711,709,699,710,588,711,601,714,713,712,699,601,589,602,603,715,716,716,716,717,717,718,596,717,704,719,614,615,615,614,705,720,720,616,720,706,721,618,707,723,722,724,723,725,724,726,715,622,727,725,714,713,713,714,728,729,729,730,716,729,731,731,731,732,732,733,733,734,734,620,735,632,736,737,634,738,722,724,738,723,741,740,638,724,639,743,725,744,622,745,639,741,741,639,744,745,745,729,729,747,731,730,731,646,737,748,636,646,748,649,741,741,745,745,746,746,747,657,749,663,749,750,751,752,749,751,753,753,754,754,755,755,755,674,674,750,750,751,751,758,753,752,759,677,760,753,761,763,759,762,680,755,678,754,754,678,762,762,755,670,764,688,756,766,757,768,758,758,692,769,768,692,770,759,771,693,772,772,773,764,693,765,772,774,775,775,774,776,775,774,764,694,685,697,696,777,777,700,778,702,779,767,703,779,703,770,770,782,781,784,707,775,782,708,776,783,777,787,777,786,788,788,788,717,789,719,790,780,791,781,790,705,789,720,793,793,720,794,792,721,781,721,785,794,783,783,783,786,786,787,787,800,788,799,800,732,789,789,793,793,794,794,796,801,797,801,798,797,798,798,799,799,800,748,801,760,803,803,803,767,805,805,802,805,806,802,802,808,803,807,808,779,804,809,805,805,805,806,806,811,808,807,808,790,809,809,810,810,811],\"k\":[2,0,0,4,3,0,0,7,5,4,7,7,12,2,14,13,13,14,18,20,16,11,5,1,6,22,8,21,15,24,22,24,16,26,16,16,29,20,28,30,30,22,30,31,22,22,25,33,27,36,35,35,28,28,29,29,40,31,31,31,32,32,36,35,37,37,38,38,45,45,12,12,13,47,50,18,51,51,19,52,51,52,53,53,54,54,23,54,58,49,27,17,33,33,56,60,62,56,60,62,39,40,65,41,33,59,61,68,67,67,69,62,67,70,70,43,72,44,39,44,44,63,68,67,69,69,70,70,77,48,78,78,50,50,81,81,52,82,81,82,53,83,85,83,83,55,87,58,58,88,87,88,89,84,55,55,86,91,64,92,93,93,66,61,61,94,71,72,98,73,64,73,73,92,95,100,100,94,68,103,103,104,104,104,76,105,106,96,102,101,103,103,104,104,110,81,80,82,81,83,82,85,114,88,87,116,116,117,110,117,117,118,118,119,119,120,89,121,89,121,124,123,123,124,124,125,128,127,122,122,123,129,97,131,98,99,131,99,100,95,95,132,105,130,134,135,131,136,132,137,139,132,137,140,140,141,141,134,141,142,144,135,135,135,138,147,146,146,139,139,140,140,151,142,142,142,147,146,148,148,149,149,155,118,117,119,118,120,119,121,120,122,160,125,124,162,162,163,155,163,163,164,164,165,165,128,167,158,167,127,168,160,161,168,160,170,131,131,173,172,172,173,136,136,172,175,143,174,136,176,136,178,145,138,138,180,150,176,182,183,185,178,178,178,180,186,188,180,186,189,189,190,190,182,190,191,193,183,183,183,186,194,186,186,198,189,189,189,190,190,191,191,195,194,196,196,203,164,163,165,164,166,165,167,207,162,203,203,209,208,210,209,211,210,171,167,212,169,207,207,214,213,209,214,208,216,216,217,217,211,171,171,220,212,213,220,212,222,222,223,224,224,177,224,227,226,226,227,184,225,179,228,179,230,234,226,187,181,192,228,235,236,228,228,231,238,232,239,239,239,197,242,242,243,243,235,243,244,235,235,236,236,238,247,250,250,248,248,252,239,251,253,253,241,253,254,241,241,242,242,243,243,244,244,260,246,246,246,249,248,251,251,252,252,253,253,254,254,255,255,256,256,257,257,258,258,270,217,216,218,217,219,273,223,222,215,270,270,276,275,277,276,224,278,278,225,279,221,273,273,281,280,282,281,283,282,284,283,285,284,229,286,286,231,287,226,279,279,289,288,281,289,280,291,291,294,282,283,284,294,283,298,284,285,299,298,238,231,300,287,288,300,287,302,302,303,304,304,305,307,298,299,247,238,309,250,250,310,309,310,260,307,312,307,260,260,261,249,249,316,316,317,317,318,318,319,319,320,320,321,321,322,322,323,323,323,269,324,325,311,315,328,327,327,316,316,317,317,318,318,319,319,320,320,321,321,336,323,323,323,328,339,338,338,341,330,330,330,331,331,332,332,333,333,334,334,339,338,347,292,291,293,349,297,352,354,350,356,354,356,358,303,302,290,347,347,361,360,304,362,362,295,349,349,305,364,364,306,351,350,354,354,356,356,368,310,309,301,358,358,371,370,372,371,361,372,360,374,374,375,375,378,363,364,312,379,379,313,380,368,369,380,368,382,382,383,383,384,384,385,377,377,324,386,386,325,389,326,388,390,380,326,387,335,391,336,394,396,392,395,396,396,398,389,397,398,340,400,400,401,401,343,403,344,344,403,335,391,393,392,396,396,397,397,398,398,408,408,340,346,346,399,400,400,401,401,415,413,419,421,417,423,421,425,423,427,425,429,427,431,429,430,431,431,416,413,413,434,438,438,436,436,439,421,417,421,421,355,440,442,353,443,423,440,355,440,443,445,355,427,427,427,429,429,431,431,432,432,435,434,434,451,437,455,454,454,456,439,454,457,457,366,366,441,457,442,458,457,458,441,444,460,357,461,463,446,446,465,464,464,447,447,448,448,469,451,451,451,470,375,374,376,375,377,455,454,456,476,475,475,457,457,460,460,462,461,461,482,481,465,465,464,466,485,484,484,468,486,487,487,382,382,490,490,491,491,385,492,491,494,470,471,495,494,387,377,476,475,477,499,498,498,478,478,482,501,485,484,503,504,504,505,487,505,508,506,494,509,510,509,391,387,499,513,512,512,501,514,515,395,394,388,503,503,503,503,521,519,506,522,402,522,522,403,404,404,513,523,524,526,526,528,525,527,515,528,393,530,529,516,532,405,531,517,534,406,517,536,534,408,408,536,409,537,519,411,411,411,412,412,524,525,528,528,530,530,532,532,534,534,546,548,544,550,548,550,552,416,555,418,419,419,420,556,419,544,544,548,548,557,424,426,558,558,559,559,430,560,559,560,433,561,433,561,553,554,554,553,566,568,568,443,568,569,571,443,569,573,573,574,435,576,562,452,453,437,437,577,566,566,581,579,459,582,582,444,570,570,462,583,583,585,585,574,572,587,587,588,576,468,589,469,578,577,590,590,592,594,474,591,593,596,579,595,597,595,598,597,479,599,599,479,465,481,481,481,483,601,601,588,586,600,589,604,468,606,604,606,608,490,489,491,490,492,491,493,594,595,476,613,614,613,596,615,593,595,614,597,617,496,616,619,499,618,497,598,619,616,619,621,598,599,501,482,600,622,600,623,502,604,604,604,505,625,606,606,505,626,625,628,608,609,629,628,508,629,629,507,615,613,617,617,631,631,632,633,621,511,634,513,633,632,633,621,501,501,639,639,637,637,623,623,641,641,644,642,628,645,521,645,645,520,635,513,514,647,636,524,646,527,526,529,638,527,649,648,652,650,637,531,654,651,640,533,533,535,654,536,642,537,537,537,538,538,647,539,540,540,541,541,542,542,543,543,658,656,545,660,660,547,546,549,547,551,664,555,556,664,555,660,545,665,665,666,666,667,557,668,670,668,668,559,558,560,559,561,560,562,663,674,566,565,677,568,568,677,678,571,569,571,571,669,679,670,681,679,681,669,683,685,669,684,686,684,687,686,576,562,689,578,578,690,580,580,676,692,680,679,683,684,574,695,696,695,685,697,683,684,585,698,587,696,686,587,686,686,589,576,689,690,700,700,700,700,580,702,691,701,702,701,580,704,596,703,692,704,708,708,706,706,698,695,695,710,699,711,588,713,715,712,713,713,589,601,603,602,602,605,603,607,702,594,717,717,596,719,704,718,719,718,596,720,614,616,721,721,722,706,721,706,706,706,709,709,711,711,602,726,727,622,714,725,726,602,726,729,715,716,625,730,730,626,625,627,719,615,630,732,631,733,722,632,735,734,736,738,634,723,740,724,724,742,638,740,639,724,744,744,725,745,622,743,745,743,725,745,729,746,747,746,644,747,747,643,735,735,737,738,738,738,741,649,652,652,654,654,655,655,749,659,750,657,749,749,665,752,752,666,665,667,666,668,667,670,756,750,757,756,758,757,676,758,758,677,759,753,760,754,761,763,680,762,678,755,763,761,763,765,764,762,755,685,756,688,756,756,758,766,757,676,692,769,769,769,770,770,772,759,771,693,693,764,772,765,773,772,773,764,777,774,775,775,685,694,696,697,697,698,766,779,779,767,766,692,778,770,781,771,771,771,785,775,707,772,775,784,777,783,710,787,787,712,710,714,778,790,790,780,778,792,791,705,790,720,789,791,792,791,795,793,781,721,782,795,783,794,797,796,798,797,799,798,727,800,800,728,789,732,733,733,734,734,736,736,796,796,739,801,801,740,742,742,744,744,801,748,802,762,761,765,804,769,768,760,802,802,807,806,774,808,808,776,804,779,804,804,810,809,811,810,785,811,811,784,809,790,792,792,795,795],\"name\":\"Pancreas\",\"opacity\":0.5,\"x\":[61.0,60.0,61.0,62.0,61.0,60.0,63.0,63.0,64.0,61.0,63.0,60.0,61.0,63.0,63.0,64.0,57.0,56.0,57.0,59.0,59.0,65.0,65.0,67.0,67.0,68.0,57.0,56.0,59.0,61.0,63.0,65.0,67.0,68.0,57.0,59.0,58.0,61.0,63.0,64.0,65.0,67.0,59.0,61.0,63.0,61.0,62.0,63.0,64.0,56.0,57.0,59.0,61.0,65.0,67.0,68.0,55.0,54.0,55.0,68.0,55.0,54.0,57.0,65.0,66.0,67.0,55.0,57.0,56.0,59.0,61.0,62.0,63.0,65.0,57.0,59.0,61.0,63.0,57.0,58.0,59.0,61.0,63.0,65.0,67.0,66.0,54.0,55.0,57.0,67.0,68.0,54.0,67.0,68.0,55.0,54.0,63.0,64.0,65.0,67.0,55.0,57.0,56.0,59.0,61.0,62.0,63.0,57.0,59.0,61.0,59.0,61.0,63.0,65.0,55.0,57.0,58.0,59.0,61.0,63.0,65.0,67.0,68.0,54.0,55.0,57.0,67.0,67.0,66.0,54.0,65.0,66.0,55.0,54.0,63.0,65.0,66.0,55.0,54.0,57.0,59.0,61.0,63.0,64.0,65.0,55.0,57.0,56.0,59.0,61.0,62.0,63.0,57.0,59.0,61.0,59.0,61.0,63.0,65.0,67.0,55.0,57.0,58.0,59.0,61.0,63.0,65.0,66.0,55.0,56.0,57.0,66.0,54.0,55.0,66.0,54.0,65.0,67.0,67.0,68.0,55.0,54.0,63.0,65.0,66.0,67.0,55.0,54.0,57.0,59.0,61.0,63.0,64.0,65.0,55.0,54.0,57.0,58.0,59.0,61.0,63.0,55.0,57.0,59.0,61.0,63.0,65.0,57.0,59.0,61.0,63.0,65.0,55.0,57.0,59.0,60.0,61.0,63.0,65.0,66.0,55.0,56.0,57.0,59.0,67.0,68.0,54.0,55.0,67.0,69.0,69.0,70.0,53.0,52.0,53.0,65.0,67.0,69.0,70.0,53.0,52.0,59.0,61.0,63.0,65.0,67.0,69.0,70.0,51.0,50.0,51.0,53.0,55.0,57.0,59.0,61.0,63.0,65.0,67.0,68.0,69.0,51.0,53.0,55.0,57.0,59.0,61.0,63.0,65.0,67.0,61.0,63.0,65.0,57.0,59.0,61.0,63.0,65.0,67.0,55.0,57.0,59.0,61.0,63.0,65.0,67.0,69.0,53.0,55.0,57.0,58.0,59.0,61.0,62.0,63.0,64.0,65.0,66.0,67.0,69.0,53.0,54.0,55.0,57.0,63.0,67.0,68.0,69.0,50.0,51.0,53.0,69.0,69.0,70.0,51.0,50.0,53.0,55.0,57.0,59.0,61.0,63.0,65.0,67.0,68.0,69.0,51.0,53.0,52.0,55.0,57.0,59.0,61.0,63.0,65.0,66.0,67.0,53.0,55.0,54.0,56.0,57.0,59.0,61.0,63.0,65.0,55.0,59.0,61.0,65.0,33.0,32.0,33.0,35.0,35.0,37.0,37.0,38.0,55.0,57.0,59.0,61.0,63.0,65.0,67.0,33.0,35.0,37.0,51.0,53.0,55.0,57.0,59.0,60.0,61.0,63.0,65.0,66.0,67.0,69.0,51.0,52.0,53.0,55.0,57.0,59.0,67.0,66.0,50.0,51.0,51.0,66.0,47.0,46.0,47.0,49.0,49.0,51.0,53.0,57.0,59.0,61.0,62.0,63.0,65.0,47.0,49.0,51.0,53.0,55.0,57.0,59.0,61.0,45.0,44.0,45.0,46.0,31.0,30.0,31.0,33.0,33.0,35.0,35.0,37.0,37.0,39.0,39.0,41.0,41.0,43.0,43.0,45.0,47.0,47.0,48.0,29.0,28.0,29.0,31.0,36.0,37.0,36.0,37.0,38.0,39.0,41.0,43.0,45.0,47.0,49.0,49.0,50.0,29.0,31.0,30.0,33.0,35.0,36.0,37.0,37.0,39.0,40.0,41.0,43.0,42.0,45.0,47.0,48.0,49.0,61.0,63.0,65.0,31.0,33.0,35.0,34.0,37.0,39.0,41.0,41.0,43.0,42.0,45.0,47.0,46.0,48.0,53.0,54.0,55.0,57.0,59.0,61.0,62.0,63.0,65.0,35.0,37.0,39.0,38.0,41.0,42.0,47.0,51.0,52.0,53.0,61.0,61.0,60.0,63.0,65.0,39.0,41.0,40.0,42.0,47.0,49.0,51.0,52.0,59.0,59.0,58.0,61.0,41.0,42.0,43.0,43.0,45.0,45.0,47.0,47.0,49.0,49.0,51.0,51.0,52.0,53.0,55.0,57.0,43.0,45.0,47.0,49.0,51.0,33.0,32.0,33.0,35.0,35.0,37.0,37.0,38.0,45.0,29.0,28.0,29.0,31.0,39.0,41.0,43.0,45.0,47.0,48.0,28.0,33.0,33.0,32.0,35.0,35.0,37.0,39.0,39.0,41.0,41.0,42.0,49.0,48.0,29.0,28.0,33.0,32.0,35.0,37.0,39.0,43.0,43.0,45.0,45.0,46.0,48.0,29.0,31.0,33.0,33.0,32.0,35.0,34.0,37.0,39.0,41.0,47.0,47.0,48.0,49.0,49.0,51.0,51.0,52.0,55.0,57.0,59.0,61.0,33.0,35.0,35.0,34.0,37.0,37.0,39.0,38.0,40.0,41.0,48.0,49.0,51.0,53.0,55.0,56.0,57.0,59.0,35.0,37.0,39.0,40.0,41.0,40.0,42.0,47.0,46.0,47.0,49.0,51.0,55.0,55.0,54.0,57.0,41.0,43.0,45.0,47.0,47.0,49.0,49.0,51.0,51.0,53.0,31.0,30.0,31.0,32.0,33.0,35.0,37.0,28.0,29.0,33.0,35.0,37.0,39.0,41.0,40.0,43.0,45.0,47.0,28.0,33.0,34.0,35.0,37.0,39.0,38.0,40.0,41.0,41.0,43.0,42.0,45.0,47.0,29.0,29.0,30.0,33.0,34.0,39.0,41.0,43.0,43.0,42.0,44.0,47.0,31.0,32.0,32.0,35.0,35.0,36.0,41.0,40.0,41.0,43.0,45.0,45.0,47.0,47.0,48.0,49.0,51.0,33.0,34.0,34.0,37.0,39.0,41.0,43.0,45.0,47.0,48.0,49.0,50.0,51.0,53.0,55.0,35.0,37.0,39.0,41.0,41.0,42.0,43.0,44.0,45.0,47.0,47.0,48.0,49.0,49.0,51.0,53.0,43.0,31.0,29.0,31.0,33.0,35.0,37.0,39.0,29.0,31.0,33.0,37.0,36.0,37.0,39.0,38.0,41.0,40.0,31.0,32.0,33.0,35.0,35.0,37.0,39.0,40.0,41.0,41.0,42.0,43.0,33.0,33.0,34.0,37.0,39.0,41.0,41.0,40.0,43.0,45.0,47.0,35.0,35.0,36.0,37.0,37.0,39.0,39.0,41.0,43.0,45.0,47.0,49.0,43.0,37.0,39.0,33.0,35.0,37.0,39.0,41.0,35.0,37.0,39.0],\"y\":[37.0,37.0,36.0,37.0,39.0,39.0,38.0,39.0,39.0,40.0,40.0,37.0,36.0,36.0,37.0,37.0,39.0,39.0,38.0,38.0,39.0,38.0,39.0,38.0,39.0,39.0,41.0,41.0,41.0,41.0,41.0,41.0,41.0,41.0,42.0,43.0,43.0,43.0,43.0,43.0,42.0,42.0,44.0,44.0,44.0,37.0,37.0,36.0,37.0,39.0,38.0,38.0,38.0,38.0,38.0,39.0,41.0,41.0,40.0,41.0,43.0,43.0,43.0,43.0,43.0,42.0,44.0,45.0,45.0,45.0,45.0,45.0,44.0,44.0,46.0,46.0,46.0,37.0,39.0,39.0,38.0,38.0,38.0,38.0,39.0,39.0,41.0,40.0,40.0,40.0,41.0,43.0,43.0,43.0,45.0,45.0,45.0,45.0,44.0,44.0,46.0,47.0,47.0,47.0,47.0,47.0,46.0,48.0,48.0,48.0,39.0,39.0,39.0,39.0,41.0,41.0,41.0,40.0,40.0,40.0,40.0,40.0,41.0,43.0,42.0,42.0,43.0,42.0,43.0,45.0,45.0,45.0,47.0,47.0,47.0,47.0,47.0,49.0,49.0,49.0,49.0,49.0,49.0,49.0,48.0,50.0,51.0,51.0,51.0,51.0,51.0,50.0,52.0,52.0,52.0,41.0,41.0,41.0,41.0,41.0,43.0,43.0,43.0,42.0,42.0,42.0,42.0,43.0,45.0,45.0,44.0,45.0,47.0,46.0,47.0,49.0,49.0,48.0,49.0,49.0,51.0,51.0,51.0,51.0,51.0,50.0,53.0,53.0,53.0,53.0,53.0,53.0,53.0,52.0,55.0,55.0,55.0,55.0,54.0,54.0,54.0,56.0,56.0,43.0,43.0,43.0,43.0,45.0,45.0,45.0,45.0,45.0,47.0,47.0,47.0,47.0,46.0,46.0,46.0,47.0,49.0,49.0,48.0,48.0,48.0,49.0,51.0,50.0,51.0,50.0,51.0,51.0,53.0,53.0,52.0,53.0,53.0,53.0,53.0,55.0,55.0,55.0,55.0,55.0,55.0,55.0,55.0,55.0,57.0,57.0,56.0,57.0,57.0,57.0,57.0,57.0,57.0,57.0,57.0,57.0,56.0,58.0,58.0,58.0,58.0,58.0,58.0,58.0,58.0,58.0,47.0,47.0,47.0,49.0,49.0,49.0,49.0,49.0,49.0,51.0,51.0,51.0,51.0,51.0,51.0,51.0,51.0,53.0,53.0,53.0,53.0,52.0,52.0,53.0,53.0,53.0,52.0,53.0,53.0,53.0,55.0,55.0,54.0,54.0,54.0,54.0,55.0,55.0,57.0,56.0,56.0,57.0,56.0,57.0,59.0,59.0,59.0,59.0,59.0,59.0,59.0,59.0,59.0,59.0,59.0,58.0,60.0,61.0,61.0,61.0,61.0,61.0,61.0,61.0,61.0,61.0,60.0,62.0,63.0,63.0,63.0,62.0,62.0,62.0,62.0,62.0,64.0,53.0,53.0,53.0,55.0,55.0,54.0,54.0,55.0,54.0,55.0,55.0,55.0,55.0,55.0,55.0,55.0,55.0,55.0,56.0,56.0,56.0,57.0,57.0,57.0,57.0,57.0,57.0,56.0,56.0,56.0,57.0,57.0,57.0,59.0,59.0,58.0,58.0,58.0,58.0,59.0,59.0,61.0,61.0,60.0,61.0,63.0,63.0,62.0,62.0,63.0,63.0,63.0,63.0,63.0,63.0,63.0,62.0,62.0,64.0,64.0,64.0,64.0,64.0,64.0,64.0,64.0,51.0,51.0,50.0,51.0,53.0,53.0,52.0,52.0,53.0,52.0,53.0,52.0,53.0,52.0,53.0,52.0,53.0,52.0,53.0,53.0,52.0,53.0,53.0,55.0,55.0,54.0,55.0,54.0,55.0,55.0,54.0,55.0,55.0,55.0,55.0,55.0,55.0,54.0,55.0,55.0,56.0,57.0,57.0,57.0,57.0,56.0,56.0,57.0,57.0,57.0,56.0,57.0,57.0,57.0,57.0,57.0,56.0,57.0,57.0,57.0,58.0,58.0,59.0,59.0,59.0,59.0,58.0,59.0,58.0,59.0,58.0,59.0,59.0,59.0,59.0,59.0,58.0,58.0,58.0,58.0,59.0,59.0,59.0,60.0,60.0,61.0,61.0,61.0,61.0,60.0,61.0,61.0,60.0,61.0,60.0,61.0,61.0,61.0,62.0,63.0,63.0,63.0,63.0,63.0,63.0,63.0,63.0,62.0,63.0,63.0,64.0,65.0,65.0,64.0,64.0,65.0,64.0,65.0,64.0,65.0,64.0,65.0,65.0,64.0,64.0,64.0,66.0,66.0,66.0,66.0,66.0,51.0,51.0,50.0,50.0,51.0,50.0,51.0,51.0,51.0,53.0,53.0,52.0,52.0,52.0,52.0,52.0,52.0,52.0,53.0,55.0,55.0,54.0,55.0,55.0,54.0,54.0,55.0,54.0,55.0,54.0,55.0,55.0,55.0,57.0,57.0,57.0,57.0,57.0,57.0,57.0,57.0,56.0,57.0,56.0,57.0,57.0,58.0,58.0,58.0,59.0,59.0,59.0,59.0,59.0,59.0,59.0,59.0,58.0,59.0,58.0,59.0,58.0,59.0,59.0,59.0,59.0,59.0,59.0,60.0,61.0,60.0,61.0,60.0,61.0,60.0,60.0,61.0,61.0,61.0,61.0,61.0,60.0,60.0,61.0,61.0,61.0,62.0,62.0,62.0,62.0,62.0,63.0,63.0,63.0,63.0,62.0,63.0,63.0,63.0,62.0,63.0,63.0,64.0,65.0,65.0,64.0,65.0,65.0,64.0,65.0,64.0,64.0,51.0,51.0,50.0,51.0,51.0,51.0,51.0,53.0,52.0,52.0,52.0,52.0,52.0,53.0,53.0,53.0,53.0,53.0,55.0,55.0,55.0,54.0,54.0,55.0,55.0,54.0,54.0,55.0,55.0,55.0,55.0,55.0,56.0,57.0,57.0,57.0,57.0,56.0,56.0,57.0,56.0,57.0,57.0,57.0,58.0,58.0,59.0,58.0,59.0,59.0,59.0,59.0,58.0,59.0,58.0,59.0,58.0,59.0,59.0,59.0,59.0,60.0,60.0,61.0,60.0,60.0,61.0,61.0,61.0,61.0,60.0,60.0,61.0,61.0,61.0,61.0,62.0,62.0,62.0,63.0,62.0,63.0,63.0,63.0,62.0,63.0,62.0,62.0,62.0,63.0,63.0,63.0,64.0,51.0,53.0,53.0,53.0,53.0,53.0,53.0,55.0,55.0,55.0,55.0,55.0,54.0,54.0,54.0,55.0,55.0,57.0,57.0,56.0,56.0,57.0,57.0,57.0,56.0,56.0,57.0,57.0,57.0,59.0,58.0,59.0,59.0,59.0,59.0,58.0,59.0,59.0,59.0,59.0,61.0,60.0,60.0,60.0,61.0,61.0,60.0,61.0,61.0,61.0,61.0,61.0,63.0,55.0,55.0,57.0,57.0,57.0,57.0,57.0,59.0,59.0,59.0],\"z\":[12.0,13.0,13.0,13.0,12.0,13.0,13.0,12.0,13.0,13.0,13.0,15.0,15.0,15.0,14.0,15.0,14.0,15.0,15.0,15.0,14.0,15.0,14.0,15.0,14.0,15.0,14.0,15.0,14.0,14.0,14.0,14.0,14.0,15.0,15.0,14.0,15.0,14.0,14.0,15.0,15.0,15.0,15.0,15.0,15.0,16.0,17.0,17.0,17.0,17.0,17.0,17.0,17.0,17.0,17.0,17.0,16.0,17.0,17.0,17.0,16.0,17.0,16.0,16.0,17.0,17.0,17.0,16.0,17.0,16.0,16.0,17.0,17.0,17.0,17.0,17.0,17.0,18.0,18.0,19.0,19.0,19.0,19.0,19.0,18.0,19.0,19.0,19.0,19.0,19.0,19.0,19.0,18.0,19.0,18.0,19.0,18.0,19.0,19.0,19.0,19.0,18.0,19.0,18.0,18.0,19.0,19.0,19.0,19.0,19.0,20.0,20.0,20.0,20.0,20.0,20.0,21.0,21.0,21.0,21.0,21.0,21.0,21.0,21.0,21.0,21.0,20.0,21.0,21.0,21.0,20.0,21.0,20.0,21.0,20.0,20.0,21.0,20.0,21.0,20.0,20.0,20.0,20.0,21.0,21.0,21.0,20.0,21.0,20.0,20.0,21.0,21.0,21.0,21.0,21.0,22.0,22.0,22.0,22.0,22.0,22.0,22.0,23.0,23.0,23.0,23.0,23.0,23.0,22.0,23.0,23.0,23.0,23.0,23.0,23.0,23.0,22.0,23.0,22.0,23.0,22.0,23.0,22.0,22.0,23.0,23.0,22.0,23.0,22.0,22.0,22.0,22.0,23.0,23.0,22.0,23.0,22.0,23.0,23.0,23.0,23.0,23.0,23.0,24.0,24.0,24.0,24.0,24.0,24.0,24.0,24.0,24.0,24.0,24.0,24.0,25.0,25.0,25.0,25.0,25.0,24.0,25.0,25.0,25.0,25.0,25.0,25.0,25.0,24.0,25.0,24.0,25.0,24.0,25.0,25.0,24.0,24.0,24.0,25.0,24.0,25.0,24.0,24.0,24.0,24.0,24.0,24.0,25.0,24.0,25.0,25.0,24.0,24.0,24.0,24.0,24.0,24.0,24.0,24.0,25.0,25.0,25.0,25.0,25.0,25.0,25.0,25.0,25.0,25.0,25.0,26.0,26.0,26.0,26.0,26.0,26.0,26.0,26.0,26.0,26.0,26.0,26.0,26.0,26.0,26.0,26.0,26.0,26.0,26.0,26.0,27.0,27.0,27.0,27.0,26.0,27.0,27.0,27.0,26.0,26.0,26.0,27.0,27.0,27.0,27.0,27.0,27.0,26.0,27.0,27.0,27.0,26.0,27.0,27.0,26.0,27.0,26.0,26.0,26.0,26.0,26.0,26.0,26.0,26.0,27.0,27.0,27.0,26.0,27.0,26.0,26.0,26.0,26.0,26.0,26.0,27.0,27.0,27.0,26.0,27.0,27.0,27.0,27.0,27.0,27.0,27.0,27.0,28.0,28.0,28.0,28.0,29.0,29.0,29.0,28.0,29.0,28.0,29.0,28.0,28.0,28.0,28.0,28.0,28.0,28.0,29.0,29.0,29.0,28.0,28.0,28.0,28.0,28.0,29.0,29.0,29.0,29.0,29.0,28.0,28.0,28.0,29.0,29.0,29.0,29.0,29.0,28.0,29.0,29.0,28.0,29.0,29.0,28.0,29.0,29.0,29.0,28.0,28.0,28.0,28.0,28.0,28.0,29.0,29.0,29.0,29.0,29.0,29.0,29.0,29.0,29.0,29.0,29.0,30.0,31.0,31.0,31.0,30.0,31.0,31.0,31.0,30.0,31.0,30.0,31.0,30.0,31.0,30.0,31.0,30.0,31.0,30.0,30.0,31.0,30.0,31.0,30.0,31.0,31.0,30.0,30.0,30.0,31.0,31.0,31.0,30.0,30.0,30.0,30.0,30.0,31.0,30.0,31.0,31.0,30.0,31.0,30.0,30.0,30.0,31.0,30.0,30.0,31.0,31.0,30.0,31.0,30.0,30.0,31.0,31.0,30.0,30.0,30.0,31.0,31.0,30.0,31.0,30.0,30.0,31.0,30.0,31.0,31.0,31.0,30.0,31.0,31.0,30.0,31.0,31.0,31.0,31.0,31.0,31.0,30.0,30.0,31.0,31.0,30.0,31.0,30.0,31.0,31.0,30.0,31.0,31.0,30.0,31.0,31.0,30.0,30.0,31.0,30.0,31.0,31.0,30.0,30.0,30.0,31.0,30.0,31.0,31.0,30.0,31.0,31.0,30.0,31.0,31.0,30.0,31.0,30.0,31.0,30.0,31.0,30.0,31.0,31.0,31.0,31.0,31.0,31.0,31.0,31.0,31.0,32.0,33.0,33.0,33.0,32.0,33.0,32.0,33.0,32.0,32.0,33.0,33.0,33.0,33.0,33.0,33.0,33.0,33.0,33.0,33.0,32.0,33.0,33.0,32.0,33.0,33.0,32.0,33.0,32.0,33.0,33.0,32.0,33.0,32.0,33.0,32.0,33.0,32.0,32.0,32.0,32.0,33.0,32.0,33.0,33.0,33.0,33.0,33.0,33.0,32.0,33.0,32.0,33.0,32.0,32.0,32.0,32.0,33.0,33.0,33.0,32.0,33.0,32.0,33.0,32.0,32.0,32.0,32.0,33.0,32.0,33.0,33.0,33.0,32.0,33.0,32.0,33.0,32.0,33.0,32.0,32.0,33.0,33.0,33.0,32.0,32.0,33.0,33.0,33.0,32.0,33.0,33.0,33.0,32.0,33.0,33.0,32.0,32.0,32.0,33.0,33.0,32.0,33.0,32.0,32.0,33.0,32.0,32.0,33.0,32.0,33.0,33.0,34.0,35.0,35.0,35.0,34.0,34.0,34.0,35.0,35.0,35.0,35.0,35.0,35.0,34.0,35.0,34.0,34.0,34.0,35.0,34.0,35.0,35.0,35.0,34.0,35.0,34.0,35.0,34.0,34.0,35.0,34.0,34.0,35.0,34.0,35.0,34.0,35.0,35.0,35.0,34.0,35.0,35.0,35.0,34.0,35.0,34.0,35.0,35.0,34.0,35.0,34.0,35.0,35.0,34.0,35.0,34.0,35.0,34.0,35.0,34.0,34.0,35.0,34.0,35.0,35.0,35.0,34.0,34.0,34.0,34.0,34.0,35.0,35.0,34.0,34.0,34.0,35.0,35.0,35.0,34.0,35.0,35.0,34.0,35.0,35.0,34.0,35.0,34.0,35.0,34.0,34.0,34.0,35.0,36.0,36.0,36.0,36.0,36.0,36.0,36.0,36.0,36.0,36.0,36.0,37.0,37.0,37.0,36.0,36.0,37.0,36.0,37.0,37.0,37.0,36.0,36.0,36.0,36.0,37.0,36.0,37.0,36.0,36.0,37.0,37.0,36.0,36.0,36.0,37.0,37.0,36.0,36.0,36.0,36.0,37.0,36.0,37.0,36.0,36.0,37.0,36.0,36.0,36.0,36.0,36.0,36.0,38.0,38.0,38.0,38.0,38.0,38.0,38.0,38.0,38.0,38.0],\"type\":\"mesh3d\"},{\"color\":\"rgb(255, 0, 0)\",\"i\":[0,2,0,3,5,7,5,5,5,5,11,11,12,13,16,17,14,18,19,19,20,20,19,22,21,23,26,27,18,28,20,29,22,30,24,31,32,31,26,28,34,29,35,30,36,31,37,32,38,38,40,42,42,41,3,3,2,45,44,46,49,50,42,51,1,1,42,4,4,52,7,7,47,8,7,7,7,55,54,56,49,59,59,49,52,62,53,63,6,6,53,8,64,13,57,15,13,13,13,65,60,62,69,63,70,70,70,63,10,64,15,66,66,66,73,21,74,23,71,76,76,77,78,73,73,74,75,82,25,75,27,33,34,33,80,80,84,36,81,37,82,32,40,86,86,87,43,41,89,89,44,44,89,46,85,39,93,92,89,91,95,96,54,54,54,54,96,56,50,61,59,59,59,100,102,97,97,96,98,106,58,58,98,65,61,99,99,68,70,69,72,72,72,109,105,111,106,112,107,113,67,107,72,77,77,114,112,115,79,79,113,73,77,84,115,80,87,87,116,88,116,86,117,119,90,90,117,94,120,95,93,101,101,122,120,123,103,103,121,97,101,109,123,104],\"j\":[1,3,4,4,6,8,9,10,11,8,5,13,13,15,10,10,18,16,14,20,18,21,21,23,23,25,17,17,28,26,29,28,30,29,31,30,24,24,33,33,33,34,34,35,35,36,36,37,39,41,41,2,41,43,44,2,43,46,46,48,39,39,51,49,4,52,52,3,45,45,6,53,53,54,54,48,47,56,56,58,59,60,49,51,62,60,63,62,9,64,64,55,9,12,13,65,65,58,57,67,68,68,68,69,69,71,63,64,17,10,66,21,73,67,74,75,75,75,76,71,17,17,79,79,78,78,74,74,82,82,83,83,84,84,35,84,34,78,78,81,81,82,39,40,87,41,41,87,88,44,43,91,91,91,50,50,86,93,90,89,91,95,95,91,48,98,98,98,59,99,61,100,93,99,103,103,102,102,96,96,107,98,106,107,68,108,68,69,109,109,110,102,109,102,102,102,105,105,106,106,113,113,76,110,114,111,111,111,115,113,112,113,83,114,114,115,86,117,117,117,93,93,116,116,120,117,119,121,121,121,100,118,122,119,119,119,123,121,120,121,108,122,122,123],\"k\":[2,0,1,0,7,5,6,9,10,12,12,14,11,14,11,16,11,11,15,14,14,22,20,24,22,24,16,26,16,16,18,18,20,20,22,22,25,32,27,26,28,28,29,29,30,30,31,31,40,42,38,1,2,2,45,44,44,47,45,47,38,49,38,38,52,42,51,45,52,53,53,47,45,55,8,54,48,57,55,57,50,61,60,60,51,51,52,52,64,53,63,12,10,55,55,66,15,65,58,66,61,60,62,62,63,72,71,71,71,71,19,19,21,73,21,23,21,25,72,17,77,27,80,78,74,81,82,81,32,25,77,27,33,83,78,35,35,35,36,36,37,37,85,85,40,40,88,88,90,88,88,46,44,48,92,85,85,85,94,94,94,97,96,95,91,56,54,58,92,100,100,93,92,101,104,102,96,105,106,105,65,107,107,67,99,101,108,108,69,108,102,109,70,104,111,110,112,111,113,112,73,67,110,76,110,110,115,114,80,115,115,79,114,83,84,84,116,88,87,90,118,116,119,118,94,120,120,95,94,97,118,100,118,118,123,122,104,123,123,103,122,108,109,109],\"name\":\"Tumor\",\"opacity\":0.5,\"x\":[37.0,36.0,37.0,38.0,37.0,41.0,40.0,41.0,42.0,41.0,42.0,43.0,43.0,45.0,45.0,46.0,43.0,42.0,45.0,47.0,47.0,49.0,49.0,51.0,51.0,52.0,43.0,42.0,45.0,47.0,49.0,51.0,52.0,43.0,45.0,47.0,49.0,51.0,33.0,32.0,33.0,35.0,35.0,37.0,39.0,39.0,41.0,41.0,42.0,33.0,32.0,35.0,37.0,39.0,43.0,43.0,45.0,45.0,46.0,33.0,35.0,34.0,37.0,39.0,41.0,47.0,47.0,48.0,35.0,37.0,39.0,41.0,40.0,48.0,49.0,51.0,41.0,42.0,47.0,47.0,46.0,49.0,51.0,43.0,45.0,33.0,34.0,35.0,37.0,39.0,38.0,41.0,33.0,34.0,39.0,41.0,43.0,42.0,45.0,35.0,35.0,36.0,41.0,41.0,40.0,43.0,45.0,47.0,37.0,39.0,41.0,43.0,45.0,47.0,43.0,45.0,35.0,37.0,35.0,37.0,39.0,41.0,37.0,39.0],\"y\":[55.0,55.0,54.0,55.0,56.0,57.0,57.0,56.0,57.0,58.0,59.0,59.0,58.0,58.0,59.0,59.0,61.0,61.0,61.0,60.0,61.0,60.0,61.0,60.0,61.0,61.0,63.0,63.0,63.0,63.0,63.0,63.0,63.0,64.0,64.0,64.0,64.0,64.0,55.0,55.0,54.0,54.0,55.0,54.0,54.0,55.0,54.0,55.0,55.0,57.0,57.0,57.0,57.0,57.0,56.0,57.0,56.0,57.0,57.0,58.0,59.0,59.0,59.0,59.0,59.0,58.0,59.0,59.0,60.0,60.0,60.0,61.0,61.0,61.0,61.0,61.0,62.0,63.0,63.0,62.0,63.0,63.0,63.0,64.0,64.0,55.0,55.0,54.0,54.0,55.0,55.0,55.0,57.0,57.0,56.0,56.0,57.0,57.0,57.0,59.0,58.0,59.0,59.0,58.0,59.0,59.0,59.0,59.0,60.0,60.0,61.0,61.0,61.0,61.0,63.0,63.0,55.0,55.0,57.0,57.0,57.0,57.0,59.0,59.0],\"z\":[30.0,31.0,31.0,31.0,31.0,30.0,31.0,31.0,31.0,31.0,31.0,30.0,31.0,31.0,30.0,31.0,30.0,31.0,30.0,31.0,30.0,31.0,30.0,31.0,30.0,31.0,30.0,31.0,30.0,30.0,30.0,30.0,31.0,31.0,31.0,31.0,31.0,31.0,32.0,33.0,33.0,33.0,32.0,33.0,33.0,32.0,33.0,32.0,33.0,32.0,33.0,32.0,32.0,32.0,33.0,32.0,33.0,32.0,33.0,33.0,32.0,33.0,32.0,32.0,32.0,33.0,32.0,33.0,33.0,33.0,33.0,32.0,33.0,33.0,32.0,32.0,33.0,33.0,32.0,33.0,33.0,32.0,32.0,33.0,33.0,34.0,35.0,35.0,35.0,34.0,35.0,34.0,34.0,35.0,35.0,35.0,34.0,35.0,34.0,34.0,35.0,35.0,34.0,35.0,35.0,34.0,34.0,34.0,35.0,35.0,34.0,34.0,34.0,34.0,34.0,34.0,36.0,36.0,36.0,36.0,36.0,36.0,36.0,36.0],\"type\":\"mesh3d\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"scene\":{\"aspectratio\":{\"x\":1,\"y\":1,\"z\":0.6666666666666666},\"camera\":{\"eye\":{\"x\":1.2,\"y\":1.2,\"z\":1.2}},\"xaxis\":{\"title\":{\"text\":\"X (RAS)\"}},\"yaxis\":{\"title\":{\"text\":\"Y (RAS)\"}},\"zaxis\":{\"title\":{\"text\":\"Z (RAS)\"}}},\"title\":{\"text\":\"3D 세분화 시각화\"}},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('67e6d1ac-8909-46c1-b3b6-1b92fc5633a4');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                            </script>        </div>\n","</body>\n","</html>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","--- 스크립트 종료 ---\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CytxQ9Hnvn8X","executionInfo":{"status":"ok","timestamp":1750983755149,"user_tz":-540,"elapsed":21714,"user":{"displayName":"구글개정","userId":"15305168374719957285"}},"outputId":"714bf7c8-7cb1-4100-a0cf-a2c6068d6315"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"wpJn11i2w4Ye","executionInfo":{"status":"aborted","timestamp":1750983706959,"user_tz":-540,"elapsed":5,"user":{"displayName":"구글개정","userId":"15305168374719957285"}}},"execution_count":null,"outputs":[]}]}